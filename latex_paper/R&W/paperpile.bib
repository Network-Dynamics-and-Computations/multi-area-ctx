@article{Uylings1991,
  title={Qualitative and quantitative comparison of the prefrontal cortex in rat and in primates, including humans},
  author={Uylings, Harry BM and van Eden, Corbert G},
  journal={Progress in brain research},
  volume={85},
  pages={31--62},
  year={1991},
  publisher={Elsevier}
}

@ARTICLE{Cunningham2014-fm,
  title         = "Linear dimensionality reduction: Survey, insights, and
                   generalizations",
  author        = "Cunningham, John P and Ghahramani, Zoubin",
  abstract      = "Linear dimensionality reduction methods are a cornerstone of
                   analyzing high dimensional data, due to their simple
                   geometric interpretations and typically attractive
                   computational properties. These methods capture many data
                   features of interest, such as covariance, dynamical
                   structure, correlation between data sets, input-output
                   relationships, and margin between data classes. Methods have
                   been developed with a variety of names and motivations in
                   many fields, and perhaps as a result the connections between
                   all these methods have not been highlighted. Here we survey
                   methods from this disparate literature as optimization
                   programs over matrix manifolds. We discuss principal
                   component analysis, factor analysis, linear multidimensional
                   scaling, Fisher's linear discriminant analysis, canonical
                   correlations analysis, maximum autocorrelation factors, slow
                   feature analysis, sufficient dimensionality reduction,
                   undercomplete independent component analysis, linear
                   regression, distance metric learning, and more. This
                   optimization framework gives insight to some rarely
                   discussed shortcomings of well-known methods, such as the
                   suboptimality of certain eigenvector solutions. Modern
                   techniques for optimization over matrix manifolds enable a
                   generic linear dimensionality reduction solver, which
                   accepts as input data and an objective to be optimized, and
                   returns, as output, an optimal low-dimensional projection of
                   the data. This simple optimization framework further allows
                   straightforward generalizations and novel variants of
                   classical methods, which we demonstrate here by creating an
                   orthogonal-projection canonical correlations analysis. More
                   broadly, this survey and generic solver suggest that linear
                   dimensionality reduction can move toward becoming a
                   blackbox, objective-agnostic numerical technology.",
  month         =  jun,
  year          =  2014,
  keywords      = "low-rank",
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML",
  eprint        = "1406.0873"
}

@ARTICLE{Kobak2018-zv,
  title         = "Optimal ridge penalty for real-world high-dimensional data
                   can be zero or negative due to the implicit ridge
                   regularization",
  author        = "Kobak, Dmitry and Lomond, Jonathan and Sanchez, Benoit",
  abstract      = "A conventional wisdom in statistical learning is that large
                   models require strong regularization to prevent overfitting.
                   Here we show that this rule can be violated by linear
                   regression in the underdetermined $n\ll p$ situation under
                   realistic conditions. Using simulations and real-life
                   high-dimensional data sets, we demonstrate that an explicit
                   positive ridge penalty can fail to provide any improvement
                   over the minimum-norm least squares estimator. Moreover, the
                   optimal value of ridge penalty in this situation can be
                   negative. This happens when the high-variance directions in
                   the predictor space can predict the response variable, which
                   is often the case in the real-world high-dimensional data.
                   In this regime, low-variance directions provide an implicit
                   ridge regularization and can make any further positive ridge
                   penalty detrimental. We prove that augmenting any linear
                   model with random covariates and using minimum-norm
                   estimator is asymptotically equivalent to adding the ridge
                   penalty. We use a spiked covariance model as an analytically
                   tractable example and prove that the optimal ridge penalty
                   in this case is negative when $n\ll p$.",
  month         =  may,
  year          =  2018,
  copyright     = "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "math.ST",
  eprint        = "1805.10939"
}

@ARTICLE{Recanatesi2019-te,
  title         = "Dimensionality compression and expansion in Deep Neural
                   Networks",
  author        = "Recanatesi, Stefano and Farrell, Matthew and Advani, Madhu
                   and Moore, Timothy and Lajoie, Guillaume and Shea-Brown,
                   Eric",
  abstract      = "Datasets such as images, text, or movies are embedded in
                   high-dimensional spaces. However, in important cases such as
                   images of objects, the statistical structure in the data
                   constrains samples to a manifold of dramatically lower
                   dimensionality. Learning to identify and extract
                   task-relevant variables from this embedded manifold is
                   crucial when dealing with high-dimensional problems. We find
                   that neural networks are often very effective at solving
                   this task and investigate why. To this end, we apply
                   state-of-the-art techniques for intrinsic dimensionality
                   estimation to show that neural networks learn
                   low-dimensional manifolds in two phases: first,
                   dimensionality expansion driven by feature generation in
                   initial layers, and second, dimensionality compression
                   driven by the selection of task-relevant features in later
                   layers. We model noise generated by Stochastic Gradient
                   Descent and show how this noise balances the dimensionality
                   of neural representations by inducing an effective
                   regularization term in the loss. We highlight the important
                   relationship between low-dimensional compressed
                   representations and generalization properties of the
                   network. Our work contributes by shedding light on the
                   success of deep neural networks in disentangling data in
                   high-dimensional space while achieving good generalization.
                   Furthermore, it invites new learning strategies focused on
                   optimizing measurable geometric properties of learned
                   representations, beginning with their intrinsic
                   dimensionality.",
  month         =  jun,
  year          =  2019,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1906.00443"
}

@ARTICLE{Steinberg2020-sd,
  title         = "A new role for circuit expansion for learning in neural
                   networks",
  author        = "Steinberg, Julia and Advani, Madhu and Sompolinsky, Haim",
  abstract      = "Many sensory pathways in the brain rely on sparsely active
                   populations of neurons downstream from the input stimuli.
                   The biological reason for the occurrence of expanded
                   structure in the brain is unclear, but may be because
                   expansion can increase the expressive power of a neural
                   network. In this work, we show that expanding a neural
                   network can improve its generalization performance even in
                   cases in which the expanded structure is pruned after the
                   learning period. To study this setting we use a
                   teacher-student framework where a perceptron teacher network
                   generates labels which are corrupted with small amounts of
                   noise. We then train a student network that is structurally
                   matched to the teacher and can achieve optimal accuracy if
                   given the teacher's synaptic weights. We find that sparse
                   expansion of the input of a student perceptron network both
                   increases its capacity and improves the generalization
                   performance of the network when learning a noisy rule from a
                   teacher perceptron when these expansions are pruned after
                   learning. We find similar behavior when the expanded units
                   are stochastic and uncorrelated with the input and analyze
                   this network in the mean field limit. We show by solving the
                   mean field equations that the generalization error of the
                   stochastic expanded student network continues to drop as the
                   size of the network increases. The improvement in
                   generalization performance occurs despite the increased
                   complexity of the student network relative to the teacher it
                   is trying to learn. We show that this effect is closely
                   related to the addition of slack variables in artificial
                   neural networks and suggest possible implications for
                   artificial and biological neural networks.",
  month         =  aug,
  year          =  2020,
  keywords      = "JC",
  archivePrefix = "arXiv",
  primaryClass  = "cond-mat.dis-nn",
  eprint        = "2008.08653"
}

@ARTICLE{Ebitz2021-sq,
  title         = "The population doctrine revolution in cognitive
                   neurophysiology",
  author        = "Ebitz, R Becket and Hayden, Benjamin Y",
  abstract      = "A major shift is happening within neurophysiology: a
                   population doctrine is drawing level with the single-neuron
                   doctrine that has long dominated the field. Population-level
                   ideas have so far had their greatest impact in motor
                   neurophysiology, but they hold incredible promise for
                   resolving open questions in cognition. Here, we codify the
                   population doctrine and survey recent work that leverages
                   this view to probe cognition. Our discussion is organized
                   around five core concepts that provide a foundation for
                   population-level thinking: (1) state spaces, (2) manifolds,
                   (3) coding dimensions, (4) subspaces, and (5) dynamics. The
                   work we review illustrates the progress and promise that
                   population neurophysiology holds for cognitive
                   neuroscience$-$for delivering new insight into attention,
                   working memory, decision-making, executive function, and
                   learning.",
  month         =  mar,
  year          =  2021,
  keywords      = "high-dimensionality",
  copyright     = "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.NC",
  eprint        = "2104.00145"
}

@ARTICLE{Marton2021-zh,
  title         = "Efficient and robust multi-task learning in the brain with
                   modular task primitives",
  author        = "Marton, Christian David and Lajoie, Guillaume and Rajan,
                   Kanaka",
  abstract      = "In a real-world setting biological agents do not have
                   infinite resources to learn new things. It is thus useful to
                   recycle previously acquired knowledge in a way that allows
                   for faster, less resource-intensive acquisition of multiple
                   new skills. Neural networks in the brain are likely not
                   entirely re-trained with new tasks, but how they leverage
                   existing computations to learn new tasks is not well
                   understood. In this work, we study this question in
                   artificial neural networks trained on commonly used
                   neuroscience paradigms. Building on recent work from the
                   multi-task learning literature, we propose two ingredients:
                   (1) network modularity, and (2) learning task primitives.
                   Together, these ingredients form inductive biases we call
                   structural and functional, respectively. Using a corpus of
                   nine different tasks, we show that a modular network endowed
                   with task primitives allows for learning multiple tasks well
                   while keeping parameter counts, and updates, low. We also
                   show that the skills acquired with our approach are more
                   robust to a broad range of perturbations compared to those
                   acquired with other multi-task learning strategies. This
                   work offers a new perspective on achieving efficient
                   multi-task learning in the brain, and makes predictions for
                   novel neuroscience experiments in which targeted
                   perturbations are employed to explore solution spaces.",
  month         =  may,
  year          =  2021,
  keywords      = "RNN;multi-task",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2105.14108"
}

@ARTICLE{Fine2021-ck,
  title         = "The whole prefrontal cortex is premotor cortex",
  author        = "Fine, Justin M and Hayden, Benjamin Y",
  abstract      = "We propose that the entirety of the prefrontal cortex can be
                   seen as fundamentally premotor in nature. By this, we mean
                   that the prefrontal cortex consists of an action abstraction
                   hierarchy whose core function is the potentiation and
                   depotentiation of possible action plans at different levels
                   of granularity. We argue that the apex of the hierarchy
                   should revolve around the process of goal selection, which
                   we posit is inherently a form of abstract action
                   optimization. Anatomical and functional evidence supports
                   the idea that this hierarchy originates on the orbital
                   surface of the brain and extends dorsally to motor cortex.
                   Our view, therefore, positions the orbitofrontal cortex as
                   the central site for the optimization of goal selection
                   policies, and suggests that other proposed roles are aspects
                   of this more general function. We conclude by proposing that
                   the dynamical systems approach, which works well in motor
                   systems, can be extended to the rest of prefrontal cortex.
                   Our proposed perspective will reframe outstanding questions,
                   open up new areas of inquiry, and will align theories of
                   prefrontal function with evolutionary principles.",
  month         =  jun,
  year          =  2021,
  keywords      = "WM",
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.NC",
  eprint        = "2106.04651"
}

@ARTICLE{Valente2021-tq,
  title         = "Probing the relationship between linear dynamical systems
                   and low-rank recurrent neural network models",
  author        = "Valente, Adrian and Ostojic, Srdjan and Pillow, Jonathan",
  abstract      = "A large body of work has suggested that neural populations
                   exhibit low-dimensional dynamics during behavior. However,
                   there are a variety of different approaches for modeling
                   low-dimensional neural population activity. One approach
                   involves latent linear dynamical system (LDS) models, in
                   which population activity is described by a projection of
                   low-dimensional latent variables with linear dynamics. A
                   second approach involves low-rank recurrent neural networks
                   (RNNs), in which population activity arises directly from a
                   low-dimensional projection of past activity. Although these
                   two modeling approaches have strong similarities, they arise
                   in different contexts and tend to have different domains of
                   application. Here we examine the precise relationship
                   between latent LDS models and linear low-rank RNNs. When can
                   one model class be converted to the other, and vice versa?
                   We show that latent LDS models can only be converted to RNNs
                   in specific limit cases, due to the non-Markovian property
                   of latent LDS models. Conversely, we show that linear RNNs
                   can be mapped onto LDS models, with latent dimensionality at
                   most twice the rank of the RNN.",
  month         =  oct,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.NC",
  eprint        = "2110.09804"
}

@article{Yin2020,
  title={Dynamics and hierarchical encoding of non-compact acoustic categories in auditory and frontal cortex},
  author={Yin, Pingbo and Strait, Dana L and Radtke-Schuller, Susanne and Fritz, Jonathan B and Shamma, Shihab A},
  journal={Current Biology},
  volume={30},
  number={9},
  pages={1649--1663},
  year={2020},
  publisher={Elsevier}
}

@ARTICLE{Williams2021-uf,
  title         = "Generalized Shape Metrics on Neural Representations",
  author        = "Williams, Alex H and Kunz, Erin and Kornblith, Simon and
                   Linderman, Scott W",
  abstract      = "Understanding the operation of biological and artificial
                   networks remains a difficult and important challenge. To
                   identify general principles, researchers are increasingly
                   interested in surveying large collections of networks that
                   are trained on, or biologically adapted to, similar tasks. A
                   standardized set of analysis tools is now needed to identify
                   how network-level covariates -- such as architecture,
                   anatomical brain region, and model organism -- impact neural
                   representations (hidden layer activations). Here, we provide
                   a rigorous foundation for these analyses by defining a broad
                   family of metric spaces that quantify representational
                   dissimilarity. Using this framework we modify existing
                   representational similarity measures based on canonical
                   correlation analysis to satisfy the triangle inequality,
                   formulate a novel metric that respects the inductive biases
                   in convolutional layers, and identify approximate Euclidean
                   embeddings that enable network representations to be
                   incorporated into essentially any off-the-shelf machine
                   learning method. We demonstrate these methods on large-scale
                   datasets from biology (Allen Institute Brain Observatory)
                   and deep learning (NAS-Bench-101). In doing so, we identify
                   relationships between neural representations that are
                   interpretable in terms of anatomical features and model
                   performance.",
  month         =  oct,
  year          =  2021,
  keywords      = "high-dimensionality ;Multi-area communication",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML",
  eprint        = "2110.14739"
}

@ARTICLE{Piantadosi2021-bw,
  title    = "The computational origin of representation",
  author   = "Piantadosi, Steven T",
  abstract = "Each of our theories of mental representation provides some
              insight into how the mind works. However, these insights often
              seem incompatible, as the debates between symbolic, dynamical,
              emergentist, sub-symbolic, and grounded approaches to cognition
              attest. Mental representations-whatever they are-must share many
              features with each of our theories of representation, and yet
              there are few hypotheses about how a synthesis could be possible.
              Here, I develop a theory of the underpinnings of symbolic
              cognition that shows how sub-symbolic dynamics may give rise to
              higher-level cognitive representations of structures, systems of
              knowledge, and algorithmic processes. This theory implements a
              version of conceptual role semantics by positing an internal
              universal representation language in which learners may create
              mental models to capture dynamics they observe in the world. The
              theory formalizes one account of how truly novel conceptual
              content may arise, allowing us to explain how even elementary
              logical and computational operations may be learned from a more
              primitive basis. I provide an implementation that learns to
              represent a variety of structures, including logic, number,
              kinship trees, regular languages, context-free languages, domains
              of theories like magnetism, dominance hierarchies, list
              structures, quantification, and computational primitives like
              repetition, reversal, and recursion. This account is based on
              simple discrete dynamical processes that could be implemented in
              a variety of different physical or biological systems. In
              particular, I describe how the required dynamics can be directly
              implemented in a connectionist framework. The resulting theory
              provides an ``assembly language'' for cognition, where high-level
              theories of symbolic computation can be implemented in simple
              dynamics that themselves could be encoded in biologically
              plausible systems.",
  journal  = "Minds Mach.",
  volume   =  31,
  pages    = "1--58",
  month    =  mar,
  year     =  2021,
  language = "en"
}

@ARTICLE{Gomez-Lavin2021-yr,
  title    = "Working memory is not a natural kind and cannot explain central
              cognition",
  author   = "Gomez-Lavin, Javier",
  abstract = "Working memory is a foundational construct of cognitive
              psychology, where it is thought to be a capacity that enables us
              to keep information in mind and to use that information to
              support goal directed behavior. Philosophers have recently
              employed working memory to explain central cognitive processes,
              from consciousness to reasoning. In this paper, I show that
              working memory cannot meet even a minimal account of natural
              kindhood, as the functions of maintenance and manipulation of
              information that tie working memory models and theories together
              do not have a coherent or univocal realizer in the brain. As
              such, working memory cannot explain central cognition. Rather, I
              argue that working memory merely redescribes its target
              phenomenon, and in doing so it obfuscates relevant distinctions
              amongst the many ways that brains like ours retain and transform
              information in the service of cognition. While this project
              ultimately erodes the explanatory role that working memory has
              played in our understanding of cognition, it simultaneously
              prompts us to evaluate the function of natural kinds within
              cognitive science, and signals the need for a productive
              pessimism to frame our future study of cognitive categories.",
  journal  = "Rev. Philos. Psychol.",
  volume   =  12,
  number   =  2,
  pages    = "199--225",
  month    =  jun,
  year     =  2021,
  keywords = "WM"
}

@INCOLLECTION{Murray2018-cn,
  title     = "Cortical Circuit Models in Psychiatry: Linking Disrupted
               {Excitation--Inhibition} Balance to Cognitive Deficits
               Associated With Schizophrenia",
  booktitle = "Computational Psychiatry",
  author    = "Murray, John D and Wang, Xiao-Jing",
  editor    = "Anticevic, Alan and Murray, John D",
  abstract  = "In this chapter, we review a series of computational modeling
               studies using biophysically based neural circuit models to study
               how disruptions of cortical excitation--inhibition (E/I) balance
               can induce cognitive deficits associated with neuropsychiatric
               disorders such as schizophrenia. Biophysically based neural
               circuit models of cognitive functions can generate dissociable
               predictions for how distinct synaptic perturbations impact
               behavior under various task paradigms. We utilized spiking
               circuit models of microcircuits in association cortical areas
               that can perform two core cognitive functions, working memory,
               and decision making. These studies revealed that E/I ratio is a
               critical property for proper cognitive function in cortical
               circuits. Furthermore, they provide a test bed for computational
               psychiatry demonstrating that neural circuit models can play a
               translational role between basic neurophysiology and clinical
               applications.",
  publisher = "Academic Press",
  pages     = "3--25",
  month     =  jan,
  year      =  2018,
  keywords  = "Biophysically based models; Decision making;
               Excitation--inhibition balance; Prefrontal cortex;
               Schizophrenia; Working memory;Schizofrenia [curr opinion]"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gold2020-iz,
  title    = "Refining the Empirical Constraints on Computational Models of
              Spatial Working Memory in Schizophrenia",
  author   = "Gold, James M and Bansal, Sonia and Anticevic, Alan and Cho,
              Youngsun T and Repov{\v s}, Grega and Murray, John D and Hahn,
              Britta and Robinson, Benjamin M and Luck, Steven J",
  abstract = "BACKGROUND: Impairments in spatial working memory (sWM) have been
              well documented in schizophrenia. Here we provide a comprehensive
              test of a microcircuit model of WM performance in schizophrenia
              that predicts enhanced effects of increasing delay duration and
              distractors based on a hypothesized imbalance of excitatory and
              inhibitory processes. METHODS: Model predictions were tested in
              41 people with schizophrenia (PSZ) and 32 healthy control
              subjects (HCS) performing an sWM task. In one condition, a single
              target location was followed by delays of 0, 2, 4, or 8 seconds.
              In a second condition, distractors were presented during the
              4-second delay interval at 20°, 30°, 40°, 50°, or 90° from the
              original target location. RESULTS: PSZ showed less precise sWM
              representations than HCS, and the rate of memory drift over time
              was greater in PSZ than in HCS. Relative to HCS, the spatial
              recall responses of PSZ were more repelled by distractors
              presented close to the target location and more attracted by
              distractors presented far from the target location. The degree of
              attraction to distant distractors was correlated with the rate of
              memory drift in the absence of distractors. CONCLUSIONS:
              Consistent with the microcircuit model, PSZ exhibited both a
              greater rate of drift and greater attraction to distant
              distractors relative to HCS. These two effects were correlated,
              consistent with the proposal that they arise from a single
              underlying mechanism. However, the repulsion effects produced by
              nearby distractors were not predicted by the model and thus
              require an updated modeling framework.",
  journal  = "Biol Psychiatry Cogn Neurosci Neuroimaging",
  volume   =  5,
  number   =  9,
  pages    = "913--922",
  month    =  sep,
  year     =  2020,
  keywords = "Computational model; Distractor effects; E-I balance; Precision;
              Schizophrenia; Working memory;Schizofrenia [curr opinion]",
  language = "en"
}

@ARTICLE{Bernardi2020,
  title    = "The Geometry of Abstraction in the Hippocampus and Prefrontal
              Cortex",
  author   = "Bernardi, Silvia and Benna, Marcus K and Rigotti, Mattia and
              Munuera, J{\'e}r{\^o}me and Fusi, Stefano and Salzman, C Daniel",
  abstract = "The curse of dimensionality plagues models of reinforcement
              learning and decision making. The process of abstraction solves
              this by constructing variables describing features shared by
              different instances, reducing dimensionality and enabling
              generalization in novel situations. Here, we characterized neural
              representations in monkeys performing a task described by
              different hidden and explicit variables. Abstraction was defined
              operationally using the generalization performance of neural
              decoders across task conditions not used for training, which
              requires a particular geometry of neural representations. Neural
              ensembles in prefrontal cortex, hippocampus, and simulated neural
              networks simultaneously represented multiple variables in a
              geometry reflecting abstraction but that still allowed a linear
              classifier to decode a large number of other variables (high
              shattering dimensionality). Furthermore, this geometry changed in
              relation to task events and performance. These findings elucidate
              how the brain and artificial systems represent variables in an
              abstract format while preserving the advantages conferred by high
              shattering dimensionality.",
  journal  = "Cell",
  volume   =  183,
  number   =  4,
  pages    = "954--967.e21",
  month    =  nov,
  year     =  2020,
  keywords = "abstraction; anterior cingulate cortex; artificial neural
              networks; dimensionality; disentangled representations;
              factorized representations; hippocampus; mixed selectivity;
              prefrontal cortex; representational geometry;high-dimensionality
              ;context-dependent",
  language = "en"
}

@ARTICLE{Spellman2021-de,
  title    = "Prefrontal deep projection neurons enable cognitive flexibility
              via persistent feedback monitoring",
  author   = "Spellman, Timothy and Svei, Malka and Kaminsky, Jesse and
              Manzano-Nieves, Gabriela and Liston, Conor",
  abstract = "Cognitive flexibility, the ability to alter strategy according to
              changing stimulus-response-reward relationships, is critical for
              updating learned behavior. Attentional set-shifting, a test of
              cognitive flexibility, depends on the activity of prefrontal
              cortex (PFC). It remains unclear, however, what role PFC neurons
              play to support set-shifting. Using optogenetics and two-photon
              calcium imaging, we demonstrate that medial PFC activity does not
              bias sensorimotor responses during set-shifting, but rather
              enables set-shifting by encoding trial feedback information, a
              role it has been known to play in other contexts. Unexpectedly,
              the functional properties of PFC cells did not vary with their
              efferent projection targets. Instead, representations of trial
              feedback formed a topological gradient, with cells more strongly
              selective for feedback information located further from the pial
              surface, where afferent input from the anterior cingulate cortex
              was denser. These findings identify a critical role for deep PFC
              projection neurons in enabling set-shifting through behavioral
              feedback monitoring.",
  journal  = "Cell",
  volume   =  184,
  number   =  10,
  pages    = "2750--2766.e17",
  month    =  may,
  year     =  2021,
  keywords = "attention; calcium imaging; cognitive flexibility; infralimbic;
              prelimbic;context-dependent",
  language = "en"
}

@ARTICLE{Fusi2016-ec,
  title    = "Why neurons mix: high dimensionality for higher cognition",
  author   = "Fusi, Stefano and Miller, Earl K and Rigotti, Mattia",
  abstract = "Neurons often respond to diverse combinations of task-relevant
              variables. This form of mixed selectivity plays an important
              computational role which is related to the dimensionality of the
              neural representations: high-dimensional representations with
              mixed selectivity allow a simple linear readout to generate a
              huge number of different potential responses. In contrast, neural
              representations based on highly specialized neurons are low
              dimensional and they preclude a linear readout from generating
              several responses that depend on multiple task-relevant
              variables. Here we review the conceptual and theoretical
              framework that explains the importance of mixed selectivity and
              the experimental evidence that recorded neural representations
              are high-dimensional. We end by discussing the implications for
              the design of future experiments.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  37,
  pages    = "66--74",
  month    =  apr,
  year     =  2016,
  keywords = "high-dimensionality",
  language = "en"
}

@ARTICLE{Li2020-ny,
  title    = "Cortico-cerebellar interactions during goal-directed behavior",
  author   = "Li, Nuo and Mrsic-Flogel, Thomas D",
  abstract = "Preparatory activity is observed across multiple interconnected
              brain regions before goal-directed movement. Preparatory activity
              reflects discrete activity states representing specific future
              actions. It is unclear how this activity is mediated by
              multi-regional interactions. Recent evidence suggests that the
              cerebellum, classically associated with fine motor control,
              contributes to preparatory activity in the neocortex. We review
              recent advances and offer perspective on the function of
              cortico-cerebellar interactions during goal-directed behavior. We
              propose that the cerebellum learns to facilitate transitions
              between neocortical activity states. Transitions between activity
              states enable flexible and appropriately timed behavioral
              responses.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  65,
  pages    = "27--37",
  month    =  sep,
  year     =  2020,
  keywords = "Multi-area communication",
  language = "en"
}

@ARTICLE{Semedo2020,
  title    = "Statistical methods for dissecting interactions between brain
              areas",
  author   = "Semedo, Jo{\~a}o D and Gokcen, Evren and Machens, Christian K and
              Kohn, Adam and Yu, Byron M",
  abstract = "The brain is composed of many functionally distinct areas. This
              organization supports distributed processing in the brain, and
              requires the coordination of signals across areas. Our
              understanding of how populations of neurons in different areas
              interact with each other is still in its infancy. As the
              availability of recordings from large populations of neurons
              across multiple brain areas increases, so does the need for
              statistical methods that are well suited for dissecting and
              interrogating these recordings. Here we review multivariate
              statistical methods that have been, or could be, applied to this
              class of recordings. By leveraging population responses, these
              methods can provide a rich description of inter-areal
              interactions. At the same time, these methods can introduce
              interpretational challenges. We thus conclude by discussing how
              to interpret the outputs of these methods to further our
              understanding of inter-areal interactions.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  65,
  pages    = "59--69",
  month    =  oct,
  year     =  2020,
  keywords = "Multi-area communication;methods",
  language = "en"
}

@ARTICLE{Kang2020-iu,
  title    = "Approaches to inferring multi-regional interactions from
              simultaneous population recordings: Inferring multi-regional
              interactions from simultaneous population recordings",
  author   = "Kang, Byungwoo and Druckmann, Shaul",
  abstract = "Most past studies of neural representations and dynamics have
              focused on recordings from single brain areas. However, growing
              evidence of brain-wide, parallel representations of cognitive
              variables suggests that analyzing neural representations and
              dynamics in individual brain areas can benefit from understanding
              the context of multi-regional interactions that support them.
              Moreover, perturbation experiments revealed that the manner in
              which these parallel representations interact with each other can
              differ dramatically across different pairs of brain areas. Recent
              advances in recording technology offer a potentially powerful
              substrate to study how multi-regional interactions coordinate
              neural representations in individual brain areas and dictate
              behavior on a single-trial basis through simultaneous recordings
              of multiple brain areas. We review pragmatic approaches to
              studying multi-regional interactions and illustrate them in the
              concrete context of a rodent delayed response task paradigm.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  65,
  pages    = "108--119",
  month    =  nov,
  year     =  2020,
  keywords = "Multi-area communication",
  language = "en"
}

@ARTICLE{Perich2020,
  title    = "Rethinking brain-wide interactions through multi-region `network
              of networks' models",
  author   = "Perich, Matthew G and Rajan, Kanaka",
  abstract = "The neural control of behavior is distributed across many
              functionally and anatomically distinct brain regions even in
              small nervous systems. While classical neuroscience models
              treated these regions as a set of hierarchically isolated nodes,
              the brain comprises a recurrently interconnected network in which
              each region is intimately modulated by many others. Uncovering
              these interactions is now possible through experimental
              techniques that access large neural populations from many brain
              regions simultaneously. Harnessing these large-scale datasets,
              however, requires new theoretical approaches. Here, we review
              recent work to understand brain-wide interactions using
              multi-region `network of networks' models and discuss how they
              can guide future experiments. We also emphasize the importance of
              multi-region recordings, and posit that studying individual
              components in isolation will be insufficient to understand the
              neural basis of behavior.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  65,
  pages    = "146--151",
  month    =  dec,
  year     =  2020,
  keywords = "Multi-area communication"
}

@ARTICLE{Keeley2020-uv,
  title    = "Modeling statistical dependencies in multi-region spike train
              data",
  author   = "Keeley, Stephen L and Zoltowski, David M and Aoi, Mikio C and
              Pillow, Jonathan W",
  abstract = "Neural computations underlying cognition and behavior rely on the
              coordination of neural activity across multiple brain areas.
              Understanding how brain areas interact to process information or
              generate behavior is thus a central question in neuroscience.
              Here we provide an overview of statistical approaches for
              characterizing statistical dependencies in multi-region spike
              train recordings. We focus on two classes of models in
              particular: regression-based models and shared latent variable
              models. Regression-based models describe interactions in terms of
              a directed transformation of information from one region to
              another. Shared latent variable models, on the other hand, seek
              to describe interactions in terms of sources that capture common
              fluctuations in spiking activity across regions. We discuss the
              advantages and limitations of each of these approaches and future
              directions for the field. We intend this review to be an
              introduction to the statistical methods in multi-region models
              for computational neuroscientists and experimentalists alike.",
  journal  = "Curr. Opin. Neurobiol.",
  month    =  dec,
  year     =  2020,
  keywords = "Multi-area communication;methods",
  language = "en"
}

@article{Riaz2019,
  title={Prelimbic and infralimbic cortical inactivations attenuate contextually driven discriminative responding for reward},
  author={Riaz, Sadia and Puveendrakumaran, Pugaliya and Khan, Dinat and Yoon, Sharon and Hamel, Laurie and Ito, Rutsuko},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--13},
  year={2019},
  publisher={Nature Publishing Group}
}

@ARTICLE{Valton2017-je,
  title    = "Comprehensive review: Computational modelling of schizophrenia",
  author   = "Valton, Vincent and Romaniuk, Liana and Douglas Steele, J and
              Lawrie, Stephen and Seri{\`e}s, Peggy",
  abstract = "Computational modelling has been used to address: (1) the variety
              of symptoms observed in schizophrenia using abstract models of
              behavior (e.g. Bayesian models - top-down descriptive models of
              psychopathology); (2) the causes of these symptoms using
              biologically realistic models involving abnormal neuromodulation
              and/or receptor imbalance (e.g. connectionist and neural networks
              - bottom-up realistic models of neural processes). These
              different levels of analysis have been used to answer different
              questions (i.e. understanding behavioral vs. neurobiological
              anomalies) about the nature of the disorder. As such, these
              computational studies have mostly supported diverging hypotheses
              of schizophrenia's pathophysiology, resulting in a literature
              that is not always expanding coherently. Some of these hypotheses
              are however ripe for revision using novel empirical evidence.
              Here we present a review that first synthesizes the literature of
              computational modelling for schizophrenia and psychotic symptoms
              into categories supporting the dopamine, glutamate, GABA,
              dysconnection and Bayesian inference hypotheses respectively.
              Secondly, we compare model predictions against the accumulated
              empirical evidence and finally we identify specific hypotheses
              that have been left relatively under-investigated.",
  journal  = "Neurosci. Biobehav. Rev.",
  volume   =  83,
  pages    = "631--646",
  month    =  dec,
  year     =  2017,
  keywords = "Computational models; Computational psychiatry; Psychotic
              symptoms; Schizophrenia;Schizofrenia [curr opinion]",
  language = "en"
}

@ARTICLE{Eliot2021-fq,
  title    = "Dump the ``dimorphism'': Comprehensive synthesis of human brain
              studies reveals few male-female differences beyond size",
  author   = "Eliot, Lise and Ahmed, Adnan and Khan, Hiba and Patel, Julie",
  abstract = "With the explosion of neuroimaging, differences between male and
              female brains have been exhaustively analyzed. Here we synthesize
              three decades of human MRI and postmortem data, emphasizing
              meta-analyses and other large studies, which collectively reveal
              few reliable sex/gender differences and a history of unreplicated
              claims. Males' brains are larger than females' from birth,
              stabilizing around 11\% in adults. This size difference accounts
              for other reproducible findings: higher white/gray matter ratio,
              intra- versus interhemispheric connectivity, and regional
              cortical and subcortical volumes in males. But when structural
              and lateralization differences are present independent of size,
              sex/gender explains only about 1\% of total variance. Connectome
              differences and multivariate sex/gender prediction are largely
              based on brain size, and perform poorly across diverse
              populations. Task-based fMRI has especially failed to find
              reproducible activation differences between men and women in
              verbal, spatial or emotion processing due to high rates of false
              discovery. Overall, male/female brain differences appear trivial
              and population-specific. The human brain is not ``sexually
              dimorphic.''",
  journal  = "Neurosci. Biobehav. Rev.",
  month    =  feb,
  year     =  2021,
  keywords = "sex; gender; brain; MRI; meta-analysis; corpus callosum; cerebral
              cortex; hippocampus; amygdala; putamen; massa intermedia;
              anterior commissure; lateralization; connectome; default mode
              network; language; verbal; spatial; mental rotation; emotion;
              empathy; precision medicine; multivariate; cortical thickness;
              neurobehavioral health; cognitive;sex differences"
}

@ARTICLE{Cohen2008-ck,
  title    = "Context-dependent changes in functional circuitry in visual area
              {MT}",
  author   = "Cohen, Marlene R and Newsome, William T",
  abstract = "Animals can flexibly change their behavior in response to a
              particular sensory stimulus; the mapping between sensory and
              motor representations in the brain must therefore be flexible as
              well. Changes in the correlated firing of pairs of neurons may
              provide a metric of changes in functional circuitry during
              behavior. We studied dynamic changes in functional circuitry by
              analyzing the noise correlations of simultaneously recorded MT
              neurons in two behavioral contexts: one that promotes cooperative
              interactions between the two neurons and another that promotes
              competitive interactions. We found that identical visual stimuli
              give rise to differences in noise correlation in the two
              contexts, suggesting that MT neurons receive inputs of central
              origin whose strength changes with the task structure. The data
              are consistent with a mixed feature-based attentional strategy
              model in which the animal sometimes alternates attention between
              opposite directions of motion and sometimes attends to the two
              directions simultaneously.",
  journal  = "Neuron",
  volume   =  60,
  number   =  1,
  pages    = "162--173",
  month    =  oct,
  year     =  2008,
  language = "en"
}

@ARTICLE{Sasaki2009,
  title    = "Dynamic readout of behaviorally relevant signals from area {MT}
              during task switching",
  author   = "Sasaki, Ryo and Uka, Takanori",
  abstract = "The processes underlying dynamic changes in human behavior during
              real situations contain much irrelevant information and represent
              a key issue facing neuroscientists. Although the roles played by
              the frontal cortex in this switching behavior have been well
              documented, little is known regarding how neural pathways
              governing sensorimotor associations accomplish such a switch. We
              addressed this question by recording activities of middle
              temporal (MT) neurons in monkeys switching between direction
              versus depth discrimination tasks. Although the monkeys
              successfully switched between the tasks, neural sensitivity did
              not change as a function of task. More importantly, neurons that
              signaled the same motor output showed trial-to-trial covariation
              between neuronal responses and perceptual judgments during both
              tasks, whereas neurons that signaled the opposite motor output
              showed no covariation in either task. These results suggest that
              task switching is accomplished via communication from distinct
              populations of neurons when sensorimotor associations switch
              within a short time period.",
  journal  = "Neuron",
  volume   =  62,
  number   =  1,
  pages    = "147--157",
  month    =  apr,
  year     =  2009,
  language = "en"
}

@ARTICLE{Li2009,
  title    = "Learning shapes the representation of behavioral choice in the
              human brain",
  author   = "Li, Sheng and Mayhew, Stephen D and Kourtzi, Zoe",
  abstract = "Making successful decisions under uncertainty due to noisy
              sensory signals is thought to benefit from previous experience.
              However, the human brain mechanisms that mediate flexible
              decisions through learning remain largely unknown. Comparing
              behavioral choices of human observers with those of a pattern
              classifier based on multivoxel single-trial fMRI signals, we show
              that category learning shapes processes related to decision
              variables in frontal and higher occipitotemporal regions rather
              than signal detection or response execution in primary visual or
              motor areas. In particular, fMRI signals in prefrontal regions
              reflect the observers' behavioral choice according to the learned
              decision criterion only in the context of the categorization
              task. In contrast, higher occipitotemporal areas show
              learning-dependent changes in the representation of perceived
              categories that are sustained after training independent of the
              task. These findings demonstrate that learning shapes selective
              representations of sensory readout signals in accordance with the
              decision criterion to support flexible decisions.",
  journal  = "Neuron",
  volume   =  62,
  number   =  3,
  pages    = "441--452",
  month    =  may,
  year     =  2009,
  language = "en"
}

@ARTICLE{Rodgers2014,
  title    = "Neural correlates of task switching in prefrontal cortex and
              primary auditory cortex in a novel stimulus selection task for
              rodents",
  author   = "Rodgers, Chris C and DeWeese, Michael R",
  abstract = "Animals can selectively respond to a target sound despite
              simultaneous distractors, just as humans can respond to one voice
              at a crowded cocktail party. To investigate the underlying neural
              mechanisms, we recorded single-unit activity in primary auditory
              cortex (A1) and medial prefrontal cortex (mPFC) of rats
              selectively responding to a target sound from a mixture. We found
              that prestimulus activity in mPFC encoded the selection
              rule-which sound from the mixture the rat should select.
              Moreover, electrically disrupting mPFC significantly impaired
              performance. Surprisingly, prestimulus activity in A1 also
              encoded selection rule, a cognitive variable typically considered
              the domain of prefrontal regions. Prestimulus changes correlated
              with stimulus-evoked changes, but stimulus tuning was not
              strongly affected. We suggest a model in which anticipatory
              activation of a specific network of neurons underlies the
              selection of a sound from a mixture, giving rise to robust and
              widespread rule encoding in both brain regions.",
  journal  = "Neuron",
  volume   =  82,
  number   =  5,
  pages    = "1157--1170",
  month    =  jun,
  year     =  2014,
  keywords = "context-dependent",
  language = "en"
}

@ARTICLE{Saez2015,
  title    = "Abstract Context Representations in Primate Amygdala and
              Prefrontal Cortex",
  author   = "Saez, A and Rigotti, M and Ostojic, S and Fusi, S and Salzman, C
              D",
  abstract = "Neurons in prefrontal cortex (PFC) encode rules, goals, and other
              abstract information thought to underlie cognitive, emotional,
              and behavioral flexibility. Here we show that the amygdala, a
              brain area traditionally thought to mediate emotions, also
              encodes abstract information that could underlie this
              flexibility. Monkeys performed a task in which
              stimulus-reinforcement contingencies varied between two sets of
              associations, each defining a context. Reinforcement prediction
              required identifying a stimulus and knowing the current context.
              Behavioral evidence indicated that monkeys utilized this
              information to perform inference and adjust their behavior.
              Neural representations in both amygdala and PFC reflected the
              linked sets of associations implicitly defining each context, a
              process requiring a level of abstraction characteristic of
              cognitive operations. Surprisingly, when errors were made, the
              context signal weakened substantially in the amygdala. These data
              emphasize the importance of maintaining abstract cognitive
              information in the amygdala to support flexible behavior.",
  journal  = "Neuron",
  volume   =  87,
  number   =  4,
  pages    = "869--881",
  month    =  aug,
  year     =  2015,
  language = "en"
}

@ARTICLE{Kell2018-if,
  title    = "A {Task-Optimized} Neural Network Replicates Human Auditory
              Behavior, Predicts Brain Responses, and Reveals a Cortical
              Processing Hierarchy",
  author   = "Kell, Alexander J E and Yamins, Daniel L K and Shook, Erica N and
              Norman-Haignere, Sam V and McDermott, Josh H",
  abstract = "A core goal of auditory neuroscience is to build quantitative
              models that predict cortical responses to natural sounds.
              Reasoning that a complete model of auditory cortex must solve
              ecologically relevant tasks, we optimized hierarchical neural
              networks for speech and music recognition. The best-performing
              network contained separate music and speech pathways following
              early shared processing, potentially replicating human cortical
              organization. The network performed both tasks as well as humans
              and exhibited human-like errors despite not being optimized to do
              so, suggesting common constraints on network and human
              performance. The network predicted fMRI voxel responses
              substantially better than traditional spectrotemporal filter
              models throughout auditory cortex. It also provided a
              quantitative signature of cortical representational
              hierarchy-primary and non-primary responses were best predicted
              by intermediate and late network layers, respectively. The
              results suggest that task optimization provides a powerful set of
              tools for modeling sensory systems.",
  journal  = "Neuron",
  volume   =  98,
  number   =  3,
  pages    = "630--644.e16",
  month    =  may,
  year     =  2018,
  keywords = "auditory cortex; convolutional neural network; deep learning;
              deep neural network; encoding models; fMRI; hierarchy; human
              auditory cortex; natural sounds; word recognition;DL vs Brain",
  language = "en"
}

@ARTICLE{Mastrogiuseppe2018,
  title    = "Linking Connectivity, Dynamics, and Computations in {Low-Rank}
              Recurrent Neural Networks",
  author   = "Mastrogiuseppe, Francesca and Ostojic, Srdjan",
  abstract = "Large-scale neural recordings have established that the
              transformation of sensory stimuli into motor outputs relies on
              low-dimensional dynamics at the population level, while
              individual neurons exhibit complex selectivity. Understanding how
              low-dimensional computations on mixed, distributed
              representations emerge from the structure of the recurrent
              connectivity and inputs to cortical networks is a major
              challenge. Here, we study a class of recurrent network models in
              which the connectivity is a sum of a random part and a minimal,
              low-dimensional structure. We show that, in such networks, the
              dynamics are low dimensional and can be directly inferred from
              connectivity using a geometrical approach. We exploit this
              understanding to determine minimal connectivity required to
              implement specific computations and find that the dynamical range
              and computational capacity quickly increase with the
              dimensionality of the connectivity structure. This framework
              produces testable experimental predictions for the relationship
              between connectivity, low-dimensional dynamics, and computational
              features of recorded neurons.",
  journal  = "Neuron",
  volume   =  99,
  number   =  3,
  pages    = "609--623.e29",
  month    =  aug,
  year     =  2018,
  keywords = "low dimensional dynamics; mixed selectivity; neural computations;
              recurrent neural networks;low-rank",
  language = "en"
}

@article{Gallego2020,
  title={Long-term stability of cortical population dynamics underlying consistent behavior},
  author={Gallego, Juan A and Perich, Matthew G and Chowdhury, Raeed H and Solla, Sara A and Miller, Lee E},
  journal={Nature neuroscience},
  volume={23},
  number={2},
  pages={260--270},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{Gozel2022,
  title={Between-area communication through the lens of within-area neuronal dynamics},
  author={Gozel, Olivia and Doiron, Brent},
  journal={bioRxiv},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}

@article{Gallego2018,
  title={Cortical population activity within a preserved neural manifold underlies multiple motor behaviors},
  author={Gallego, Juan A and Perich, Matthew G and Naufel, Stephanie N and Ethier, Christian and Solla, Sara A and Miller, Lee E},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--13},
  year={2018},
  publisher={Nature Publishing Group}
}

@ARTICLE{Perich2018,
  title    = "A Neural Population Mechanism for Rapid Learning",
  author   = "Perich, Matthew G and Gallego, Juan A and Miller, Lee E",
  abstract = "Long-term learning of language, mathematics, and motor skills
              likely requires cortical plasticity, but behavior often requires
              much faster changes, sometimes even after single errors. Here, we
              propose one neural mechanism to rapidly develop new motor output
              without altering the functional connectivity within or between
              cortical areas. We tested cortico-cortical models relating the
              activity of hundreds of neurons in the premotor (PMd) and primary
              motor (M1) cortices throughout adaptation to reaching movement
              perturbations. We found a signature of learning in the
              ``output-null'' subspace of PMd with respect to M1 reflecting the
              ability of premotor cortex to alter preparatory activity without
              directly influencing M1. The output-null subspace planning
              activity evolved with adaptation, yet the ``output-potent''
              mapping that captures information sent to M1 was preserved. Our
              results illustrate a population-level cortical mechanism to
              progressively adjust the output from one brain area to its
              downstream structures that could be exploited for rapid
              behavioral adaptation.",
  journal  = "Neuron",
  volume   =  100,
  number   =  4,
  pages    = "964--976.e7",
  month    =  nov,
  year     =  2018,
  keywords = "functional connectivity; monkeys; motor cortex; motor learning;
              neural manifold; nonhuman primates; premotor cortex; single
              neurons;Multi-area communication",
  language = "en"
}

@ARTICLE{Semedo2019,
  title    = "Cortical Areas Interact through a Communication Subspace",
  author   = "Semedo, Jo{\~a}o D and Zandvakili, Amin and Machens, Christian K
              and Yu, Byron M and Kohn, Adam",
  abstract = "Most brain functions involve interactions among multiple,
              distinct areas or nuclei. For instance, visual processing in
              primates requires the appropriate relaying of signals across many
              distinct cortical areas. Yet our understanding of how populations
              of neurons in interconnected brain areas communicate is in its
              infancy. Here we investigate how trial-to-trial fluctuations of
              population responses in primary visual cortex (V1) are related to
              simultaneously recorded population responses in area V2. Using
              dimensionality reduction methods, we find that V1-V2 interactions
              occur through a communication subspace: V2 fluctuations are
              related to a small subset of V1 population activity patterns,
              distinct from the largest fluctuations shared among neurons
              within V1. In contrast, interactions between subpopulations
              within V1 are less selective. We propose that the communication
              subspace may be a general, population-level mechanism by which
              activity can be selectively routed across brain areas.",
  journal  = "Neuron",
  volume   =  102,
  number   =  1,
  pages    = "249--259.e4",
  month    =  apr,
  year     =  2019,
  keywords = "area V2; corticocortical; dimensionality reduction; inter-areal
              communication; macaque; neural population; neural variability;
              primary visual cortex; vision; visual cortex;Multi-area
              communication",
  language = "en"
}

@ARTICLE{Cayco-Gajic2019-ma,
  title    = "Re-evaluating Circuit Mechanisms Underlying Pattern Separation",
  author   = "Cayco-Gajic, N Alex and Silver, R Angus",
  abstract = "When animals interact with complex environments, their neural
              circuits must separate overlapping patterns of activity that
              represent sensory and motor information. Pattern separation is
              thought to be a key function of several brain regions, including
              the cerebellar cortex, insect mushroom body, and dentate gyrus.
              However, recent findings have questioned long-held ideas on how
              these circuits perform this fundamental computation. Here, we
              re-evaluate the functional and structural mechanisms underlying
              pattern separation. We argue that the dimensionality of the space
              available for population codes representing sensory and motor
              information provides a common framework for understanding pattern
              separation. We then discuss how these three circuits use
              different strategies to separate activity patterns and facilitate
              associative learning in the presence of trial-to-trial
              variability.",
  journal  = "Neuron",
  volume   =  101,
  number   =  4,
  pages    = "584--602",
  month    =  feb,
  year     =  2019,
  keywords = "cerebellum; decorrelation; dimensionality; hippocampus; insect
              mushroom body; neural circuits; pattern separation; sensorimotor
              processing; sparse coding; sparse
              connectivity;high-dimensionality",
  language = "en"
}

@ARTICLE{Hasson2020-od,
  title    = "Direct Fit to Nature: An Evolutionary Perspective on Biological
              and Artificial Neural Networks",
  author   = "Hasson, Uri and Nastase, Samuel A and Goldstein, Ariel",
  abstract = "Evolution is a blind fitting process by which organisms become
              adapted to their environment. Does the brain use similar
              brute-force fitting processes to learn how to perceive and act
              upon the world? Recent advances in artificial neural networks
              have exposed the power of optimizing millions of synaptic weights
              over millions of observations to operate robustly in real-world
              contexts. These models do not learn simple, human-interpretable
              rules or representations of the world; rather, they use local
              computations to interpolate over task-relevant manifolds in a
              high-dimensional parameter space. Counterintuitively, similar to
              evolutionary processes, over-parameterized models can be simple
              and parsimonious, as they provide a versatile, robust solution
              for learning a diverse set of functions. This new family of
              direct-fit models present a radical challenge to many of the
              theoretical assumptions in psychology and neuroscience. At the
              same time, this shift in perspective establishes unexpected links
              with developmental and ecological psychology.",
  journal  = "Neuron",
  volume   =  105,
  number   =  3,
  pages    = "416--434",
  month    =  feb,
  year     =  2020,
  keywords = "evolution; experimental design; interpolation; learning; neural
              networks;DL vs Brain;evolution",
  language = "en"
}

@ARTICLE{Sherman2021-jc,
  title    = "Cortical control of behavior and attention from an evolutionary
              perspective",
  author   = "Sherman, S Murray and Usrey, W Martin",
  abstract = "For animals to survive, they must interact with their
              environment, taking in sensory information and making appropriate
              motor responses. Early on during vertebrate evolution, this was
              accomplished with neural circuits located mostly within the
              spinal cord and brainstem. As the cerebral cortex evolved, it
              provided additional and powerful advantages for assessing
              environmental cues and guiding appropriate responses.
              Importantly, the cerebral cortex was added onto an already
              functional nervous system. Moreover, every cortical area,
              including areas traditionally considered sensory, provides input
              to the subcortical motor structures that are bottlenecks for
              driving action. These facts have important ramifications for
              cognitive aspects of motor control. Here we consider the
              evolution of cortical mechanisms for attention from the
              perspective of having to work through these subcortical
              bottlenecks. From this perspective, many features of attention
              can be explained, including the preferential engagement of some
              cortical areas at the cost of disengagement from others to
              improve appropriate behavioral responses.",
  journal  = "Neuron",
  month    =  jul,
  year     =  2021,
  keywords = "context-dependent",
  language = "en"
}

@ARTICLE{Hennig2021-ut,
  title    = "How learning unfolds in the brain: toward an optimization view",
  author   = "Hennig, Jay A and Oby, Emily R and Losey, Darby M and Batista,
              Aaron P and Yu, Byron M and Chase, Steven M",
  abstract = "How do changes in the brain lead to learning? To answer this
              question, consider an artificial neural network (ANN), where
              learning proceeds by optimizing a given objective or cost
              function. This ``optimization framework'' may provide new
              insights into how the brain learns, as many idiosyncratic
              features of neural activity can be recapitulated by an ANN
              trained to perform the same task. Nevertheless, there are key
              features of how neural population activity changes throughout
              learning that cannot be readily explained in terms of
              optimization and are not typically features of ANNs. Here we
              detail three of these features: (1) the inflexibility of neural
              variability throughout learning, (2) the use of multiple learning
              processes even during simple tasks, and (3) the presence of large
              task-nonspecific activity changes. We propose that understanding
              the role of these features in the brain will be key to describing
              biological learning using an optimization framework.",
  journal  = "Neuron",
  month    =  oct,
  year     =  2021,
  language = "en"
}

@ARTICLE{Clemens2021-tk,
  title    = "Navigating clues to success in academia",
  author   = "Clemens, Ann M and Khodakhah, Kamran and Fenton, Andr{\'e} A",
  abstract = "Academic success and how to achieve it takes diverse forms,
              depending on who's asked. We suggest that happiness, impact, and
              longevity can be achieved with professional effort and support
              that balances the toil and joys of one's chosen path.",
  journal  = "Neuron",
  volume   =  109,
  number   =  21,
  pages    = "3368--3372",
  month    =  nov,
  year     =  2021,
  keywords = "academia life",
  language = "en"
}

@ARTICLE{Flesch2022,
  title    = "Orthogonal representations for robust context-dependent task
              performance in brains and neural networks",
  author   = "Flesch, Timo and Juechems, Keno and Dumbalska, Tsvetomira and
              Saxe, Andrew and Summerfield, Christopher",
  abstract = "How do neural populations code for multiple, potentially
              conflicting tasks? Here we used computational simulations
              involving neural networks to define ``lazy'' and ``rich'' coding
              solutions to this context-dependent decision-making problem,
              which trade off learning speed for robustness. During lazy
              learning the input dimensionality is expanded by random
              projections to the network hidden layer, whereas in rich learning
              hidden units acquire structured representations that privilege
              relevant over irrelevant features. For context-dependent
              decision-making, one rich solution is to project task
              representations onto low-dimensional and orthogonal manifolds.
              Using behavioral testing and neuroimaging in humans and analysis
              of neural signals from macaque prefrontal cortex, we report
              evidence for neural coding patterns in biological brains whose
              dimensionality and neural geometry are consistent with the rich
              learning regime.",
  journal  = "Neuron",
  month    =  jan,
  year     =  2022,
  keywords = "artificial neural networks; functional magnetic resonance
              imaging; orthogonal manifolds; representational geometry; task
              learning;context-dependent",
  language = "en"
}

@ARTICLE{Stokes2015-ph,
  title    = "'Activity-silent' working memory in prefrontal cortex: a dynamic
              coding framework",
  author   = "Stokes, Mark G",
  abstract = "Working memory (WM) provides the functional backbone to
              high-level cognition. Maintenance in WM is often assumed to
              depend on the stationary persistence of neural activity patterns
              that represent memory content. However, accumulating evidence
              suggests that persistent delay activity does not always accompany
              WM maintenance but instead seems to wax and wane as a function of
              the current task relevance of memoranda. Furthermore, new methods
              for measuring and analysing population-level patterns show that
              activity states are highly dynamic. At first glance, these
              dynamics seem at odds with the very nature of WM. How can we keep
              a stable thought in mind while brain activity is constantly
              changing? This review considers how neural dynamics might be
              functionally important for WM maintenance.",
  journal  = "Trends Cogn. Sci.",
  volume   =  19,
  number   =  7,
  pages    = "394--405",
  month    =  jul,
  year     =  2015,
  keywords = "activity-silent",
  language = "en"
}

@ARTICLE{Kohn2020,
  title    = "Principles of Corticocortical Communication: Proposed Schemes and
              Design Considerations",
  author   = "Kohn, Adam and Jasper, Anna I and Semedo, Jo{\~a}o D and Gokcen,
              Evren and Machens, Christian K and Yu, Byron M",
  abstract = "Nearly all brain functions involve routing neural activity among
              a distributed network of areas. Understanding this routing
              requires more than a description of interareal anatomical
              connectivity: it requires understanding what controls the flow of
              signals through interareal circuitry and how this communication
              might be modulated to allow flexible behavior. Here we review
              proposals of how communication, particularly between visual
              cortical areas, is instantiated and modulated, highlighting
              recent work that offers new perspectives. We suggest
              transitioning from a focus on assessing changes in the strength
              of interareal interactions, as often seen in studies of
              interareal communication, to a broader consideration of how
              different signaling schemes might contribute to computation. To
              this end, we discuss a set of features that might be desirable
              for a communication scheme.",
  journal  = "Trends Neurosci.",
  month    =  aug,
  year     =  2020,
  keywords = "communication subspace; communication through coherence;
              corticocortical communication; feedback; feedforward; interareal
              signaling; pulvinar; synchrony; visual cortex;Multi-area
              communication",
  language = "en"
}

@ARTICLE{Wang2021-um,
  title    = "50 years of mnemonic persistent activity: quo vadis?",
  author   = "Wang, Xiao-Jing",
  abstract = "Half a century ago persistent spiking activity in the neocortex
              was discovered to be a neural substrate of working memory. Since
              then scientists have sought to understand this core cognitive
              function across biological and computational levels. Studies are
              reviewed here that cumulatively lend support to a synaptic theory
              of recurrent circuits for mnemonic persistent activity that
              depends on various cellular and network substrates and is
              mathematically described by a multiple-attractor network model.
              Crucially, a mnemonic attractor state of the brain is consistent
              with temporal variations and heterogeneity across neurons in a
              subspace of population activity. Persistent activity should be
              broadly understood as a contrast to decaying transients.
              Mechanisms in the absence of neural firing ('activity-silent
              state') are suitable for passive short-term memory but not for
              working memory -- which is characterized by executive control for
              filtering out distractors, limited capacity, and internal
              manipulation of information.",
  journal  = "Trends Neurosci.",
  month    =  oct,
  year     =  2021,
  keywords = "working memory; persistent activity; multiple-attractor network
              model; NMDA receptor; diverse interneuron types; activity-silent
              state; short-term memory; subspace analysis; cognition;
              psychiatry"
}

@ARTICLE{Liebeskind2016-ep,
  title    = "Complex Homology and the Evolution of Nervous Systems",
  author   = "Liebeskind, Benjamin J and Hillis, David M and Zakon, Harold H
              and Hofmann, Hans A",
  abstract = "We examine the complex evolution of animal nervous systems and
              discuss the ramifications of this complexity for inferring the
              nature of early animals. Although reconstructing the origins of
              nervous systems remains a central challenge in biology, and the
              phenotypic complexity of early animals remains controversial, a
              compelling picture is emerging. We now know that the nervous
              system and other key animal innovations contain a large degree of
              homoplasy, at least on the molecular level. Conflicting
              hypotheses about early nervous system evolution are due primarily
              to differences in the interpretation of this homoplasy. We
              highlight the need for explicit discussion of assumptions and
              discuss the limitations of current approaches for inferring
              ancient phenotypic states.",
  journal  = "Trends Ecol. Evol.",
  volume   =  31,
  number   =  2,
  pages    = "127--135",
  month    =  feb,
  year     =  2016,
  keywords = "evolution;DL vs Brain",
  language = "en"
}

@ARTICLE{Mante2013,
  title    = "Context-dependent computation by recurrent dynamics in prefrontal
              cortex",
  author   = "Mante, Valerio and Sussillo, David and Shenoy, Krishna V and
              Newsome, William T",
  abstract = "Prefrontal cortex is thought to have a fundamental role in
              flexible, context-dependent behaviour, but the exact nature of
              the computations underlying this role remains largely unknown. In
              particular, individual prefrontal neurons often generate
              remarkably complex responses that defy deep understanding of
              their contribution to behaviour. Here we study prefrontal cortex
              activity in macaque monkeys trained to flexibly select and
              integrate noisy sensory inputs towards a choice. We find that the
              observed complexity and functional roles of single neurons are
              readily understood in the framework of a dynamical process
              unfolding at the level of the population. The population dynamics
              can be reproduced by a trained recurrent neural network, which
              suggests a previously unknown mechanism for selection and
              integration of task-relevant inputs. This mechanism indicates
              that selection and integration are two aspects of a single
              dynamical process unfolding within the same prefrontal circuits,
              and potentially provides a novel, general framework for
              understanding context-dependent computations.",
  journal  = "Nature",
  volume   =  503,
  number   =  7474,
  pages    = "78--84",
  month    =  nov,
  year     =  2013,
  keywords = "context-dependent",
  language = "en"
}

@ARTICLE{Wimmer2015-mg,
  title    = "Thalamic control of sensory selection in divided attention",
  author   = "Wimmer, Ralf D and Schmitt, L Ian and Davidson, Thomas J and
              Nakajima, Miho and Deisseroth, Karl and Halassa, Michael M",
  abstract = "How the brain selects appropriate sensory inputs and suppresses
              distractors is unknown. Given the well-established role of the
              prefrontal cortex (PFC) in executive function, its interactions
              with sensory cortical areas during attention have been
              hypothesized to control sensory selection. To test this idea and,
              more generally, dissect the circuits underlying sensory
              selection, we developed a cross-modal divided-attention task in
              mice that allowed genetic access to this cognitive process. By
              optogenetically perturbing PFC function in a temporally precise
              window, the ability of mice to select appropriately between
              conflicting visual and auditory stimuli was diminished.
              Equivalent sensory thalamocortical manipulations showed that
              behaviour was causally dependent on PFC interactions with the
              sensory thalamus, not sensory cortex. Consistent with this
              notion, we found neurons of the visual thalamic reticular nucleus
              (visTRN) to exhibit PFC-dependent changes in firing rate
              predictive of the modality selected. visTRN activity was causal
              to performance as confirmed by bidirectional optogenetic
              manipulations of this subnetwork. Using a combination of
              electrophysiology and intracellular chloride photometry, we
              demonstrated that visTRN dynamically controls visual thalamic
              gain through feedforward inhibition. Our experiments introduce a
              new subcortical model of sensory selection, in which the PFC
              biases thalamic reticular subnetworks to control thalamic sensory
              gain, selecting appropriate inputs for further processing.",
  journal  = "Nature",
  volume   =  526,
  number   =  7575,
  pages    = "705--709",
  month    =  oct,
  year     =  2015,
  keywords = "context-dependent",
  language = "en"
}

@ARTICLE{Carcea2017-ey,
  title    = "Dynamics of auditory cortical activity during behavioural
              engagement and auditory perception",
  author   = "Carcea, Ioana and Insanally, Michele N and Froemke, Robert C",
  abstract = "Behavioural engagement can enhance sensory perception. However,
              the neuronal mechanisms by which behavioural states affect
              stimulus perception remain poorly understood. Here we record from
              single units in auditory cortex of rats performing a
              self-initiated go/no-go auditory task. Self-initiation transforms
              cortical tuning curves and bidirectionally modulates
              stimulus-evoked activity patterns and improves auditory detection
              and recognition. Trial self-initiation decreases the rate of
              spontaneous activity in the majority of recorded cells.
              Optogenetic disruption of cortical activity before and during
              tone presentation shows that these changes in evoked and
              spontaneous activity are important for sound perception. Thus,
              behavioural engagement can prepare cortical circuits for sensory
              processing by dynamically changing sound representation and by
              controlling the pattern of spontaneous activity.",
  journal  = "Nat. Commun.",
  volume   =  8,
  pages    = "14412",
  month    =  feb,
  year     =  2017,
  keywords = "saturating non-linearities",
  language = "en"
}

@ARTICLE{Deneve2016-ss,
  title    = "Efficient codes and balanced networks",
  author   = "Den{\`e}ve, Sophie and Machens, Christian K",
  abstract = "Recent years have seen a growing interest in inhibitory
              interneurons and their circuits. A striking property of cortical
              inhibition is how tightly it balances excitation. Inhibitory
              currents not only match excitatory currents on average, but track
              them on a millisecond time scale, whether they are caused by
              external stimuli or spontaneous fluctuations. We review, together
              with experimental evidence, recent theoretical approaches that
              investigate the advantages of such tight balance for coding and
              computation. These studies suggest a possible revision of the
              dominant view that neurons represent information with firing
              rates corrupted by Poisson noise. Instead, tight
              excitatory/inhibitory balance may be a signature of a highly
              cooperative code, orders of magnitude more precise than a Poisson
              rate code. Moreover, tight balance may provide a template that
              allows cortical neurons to construct high-dimensional population
              codes and learn complex functions of their inputs.",
  journal  = "Nat. Neurosci.",
  volume   =  19,
  number   =  3,
  pages    = "375--382",
  month    =  mar,
  year     =  2016,
  language = "en"
}

@article{Fritz2010,
  title={Adaptive, behaviorally gated, persistent encoding of task-relevant auditory information in ferret frontal cortex},
  author={Fritz, Jonathan B and David, Stephen V and Radtke-Schuller, Susanne and Yin, Pingbo and Shamma, Shihab A},
  journal={Nature neuroscience},
  volume={13},
  number={8},
  pages={1011--1019},
  year={2010},
  publisher={Nature Publishing Group}
}

@ARTICLE{Bagur2018,
  title    = "{Go/No-Go} task engagement enhances population representation of
              target stimuli in primary auditory cortex",
  author   = "Bagur, Sophie and Averseng, Martin and Elgueda, Diego and David,
              Stephen and Fritz, Jonathan and Yin, Pingbo and Shamma, Shihab
              and Boubenec, Yves and Ostojic, Srdjan",
  abstract = "Primary sensory cortices are classically considered to extract
              and represent stimulus features, while association and
              higher-order areas are thought to carry information about
              stimulus meaning. Here we show that this information can in fact
              be found in the neuronal population code of the primary auditory
              cortex (A1). A1 activity was recorded in awake ferrets while they
              either passively listened or actively discriminated stimuli in a
              range of Go/No-Go paradigms, with different sounds and
              reinforcements. Population-level dimensionality reduction
              techniques reveal that task engagement induces a shift in
              stimulus encoding from a sensory to a behaviorally driven
              representation that specifically enhances the target stimulus in
              all paradigms. This shift partly relies on
              task-engagement-induced changes in spontaneous activity.
              Altogether, we show that A1 population activity bears strong
              similarities to frontal cortex responses. These findings indicate
              that primary sensory cortices implement a crucial change in the
              structure of population activity to extract task-relevant
              information during behavior.",
  journal  = "Nat. Commun.",
  volume   =  9,
  number   =  1,
  pages    = "2529",
  month    =  jun,
  year     =  2018,
  language = "en"
}

@ARTICLE{Snyder2018-xr,
  title    = "Distinct population codes for attention in the absence and
              presence of visual stimulation",
  author   = "Snyder, Adam C and Yu, Byron M and Smith, Matthew A",
  abstract = "Visual neurons respond more vigorously to an attended stimulus
              than an unattended one. How the brain prepares for response gain
              in anticipation of that stimulus is not well understood. One
              prominent proposal is that anticipation is characterized by
              gain-like modulations of spontaneous activity similar to gains in
              stimulus responses. Here we test an alternative idea:
              anticipation is characterized by a mixture of both increases and
              decreases of spontaneous firing rates. Such a strategy would be
              adaptive as it supports a simple linear scheme for disentangling
              internal, modulatory signals from external, sensory inputs. We
              recorded populations of V4 neurons in monkeys performing an
              attention task, and found that attention states are signaled by
              different mixtures of neurons across the population in the
              presence or absence of a stimulus. Our findings support a move
              from a stimulation-invariant account of anticipation towards a
              richer view of attentional modulation in a diverse neuronal
              population.",
  journal  = "Nat. Commun.",
  volume   =  9,
  number   =  1,
  pages    = "4382",
  month    =  oct,
  year     =  2018,
  keywords = "saturating non-linearities",
  language = "en"
}

@ARTICLE{Birman2019,
  title    = "A flexible readout mechanism of human sensory representations",
  author   = "Birman, Daniel and Gardner, Justin L",
  abstract = "Attention can both enhance and suppress cortical sensory
              representations. However, changing sensory representations can
              also be detrimental to behavior. Behavioral consequences can be
              avoided by flexibly changing sensory readout, while leaving the
              representations unchanged. Here, we asked human observers to
              attend to and report about either one of two features which
              control the visibility of motion while making concurrent
              measurements of cortical activity with BOLD imaging (fMRI). We
              extend a well-established linking model to account for the
              relationship between these measurements and find that changes in
              sensory representation during directed attention are insufficient
              to explain perceptual reports. Adding a flexible downstream
              readout is necessary to best explain our data. Such a model
              implies that observers should be able to recover information
              about ignored features, a prediction which we confirm
              behaviorally. Thus, flexible readout is a critical component of
              the cortical implementation of human adaptive behavior.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "3500",
  month    =  aug,
  year     =  2019,
  language = "en"
}

@ARTICLE{Shenoy2021-hk,
  title    = "Measurement, manipulation and modeling of brain-wide neural
              population dynamics",
  author   = "Shenoy, Krishna V and Kao, Jonathan C",
  abstract = "Neural recording technologies increasingly enable simultaneous
              measurement of neural activity from multiple brain areas. To gain
              insight into distributed neural computations, a commensurate
              advance in experimental and analytical methods is necessary. We
              discuss two opportunities towards this end: the manipulation and
              modeling of neural population dynamics.",
  journal  = "Nat. Commun.",
  volume   =  12,
  number   =  1,
  pages    = "633",
  month    =  jan,
  year     =  2021,
  keywords = "Multi-area communication"
}

@ARTICLE{Quinn2021-fg,
  title    = "Decision-related feedback in visual cortex lacks spatial
              selectivity",
  author   = "Quinn, Katrina R and Seillier, Lenka and Butts, Daniel A and
              Nienborg, Hendrikje",
  abstract = "Feedback in the brain is thought to convey contextual information
              that underlies our flexibility to perform different tasks.
              Empirical and computational work on the visual system suggests
              this is achieved by targeting task-relevant neuronal
              subpopulations. We combine two tasks, each resulting in selective
              modulation by feedback, to test whether the feedback reflected
              the combination of both selectivities. We used visual
              feature-discrimination specified at one of two possible locations
              and uncoupled the decision formation from motor plans to report
              it, while recording in macaque mid-level visual areas. Here we
              show that although the behavior is spatially selective, using
              only task-relevant information, modulation by decision-related
              feedback is spatially unselective. Population responses reveal
              similar stimulus-choice alignments irrespective of stimulus
              relevance. The results suggest a common mechanism across tasks,
              independent of the spatial selectivity these tasks demand. This
              may reflect biological constraints and facilitate generalization
              across tasks. Our findings also support a previously hypothesized
              link between feature-based attention and decision-related
              activity.",
  journal  = "Nat. Commun.",
  volume   =  12,
  number   =  1,
  pages    = "4473",
  month    =  jul,
  year     =  2021,
  keywords = "context-dependent",
  language = "en"
}

@article{Takagi2021,
  title={Adapting non-invasive human recordings along multiple task-axes shows unfolding of spontaneous and over-trained choice},
  author={Takagi, Yu and Hunt, Laurence Tudor and Woolrich, Mark W and Behrens, Timothy EJ and Klein-Fl{\"u}gge, Miriam C},
  journal={Elife},
  volume={10},
  pages={e60988},
  year={2021},
  publisher={eLife Sciences Publications Limited}
}

@ARTICLE{Ito2022-rk,
  title    = "Constructing neural network models from brain data reveals
              representational transformations linked to adaptive behavior",
  author   = "Ito, Takuya and Yang, Guangyu Robert and Laurent, Patryk and
              Schultz, Douglas H and Cole, Michael W",
  abstract = "The human ability to adaptively implement a wide variety of tasks
              is thought to emerge from the dynamic transformation of cognitive
              information. We hypothesized that these transformations are
              implemented via conjunctive activations in ``conjunction
              hubs''-brain regions that selectively integrate sensory,
              cognitive, and motor activations. We used recent advances in
              using functional connectivity to map the flow of activity between
              brain regions to construct a task-performing neural network model
              from fMRI data during a cognitive control task. We verified the
              importance of conjunction hubs in cognitive computations by
              simulating neural activity flow over this empirically-estimated
              functional connectivity model. These empirically-specified
              simulations produced above-chance task performance (motor
              responses) by integrating sensory and task rule activations in
              conjunction hubs. These findings reveal the role of conjunction
              hubs in supporting flexible cognitive computations, while
              demonstrating the feasibility of using empirically-estimated
              neural network models to gain insight into cognitive computations
              in the human brain.",
  journal  = "Nat. Commun.",
  volume   =  13,
  number   =  1,
  pages    = "673",
  month    =  feb,
  year     =  2022,
  keywords = "context-dependent",
  language = "en"
}

@ARTICLE{Barack2021-ja,
  title    = "Two views on the cognitive brain",
  author   = "Barack, David L and Krakauer, John W",
  abstract = "Cognition can be defined as computation over meaningful
              representations in the brain to produce adaptive behaviour. There
              are two views on the relationship between cognition and the brain
              that are largely implicit in the literature. The Sherringtonian
              view seeks to explain cognition as the result of operations on
              signals performed at nodes in a network and passed between them
              that are implemented by specific neurons and their connections in
              circuits in the brain. The contrasting Hopfieldian view explains
              cognition as the result of transformations between or movement
              within representational spaces that are implemented by neural
              populations. Thus, the Hopfieldian view relegates details
              regarding the identity of and connections between specific
              neurons to the status of secondary explainers. Only the
              Hopfieldian approach has the representational and computational
              resources needed to develop novel neurofunctional objects that
              can serve as primary explainers of cognition.",
  journal  = "Nat. Rev. Neurosci.",
  month    =  apr,
  year     =  2021,
  keywords = "high-dimensionality",
  language = "en"
}

@ARTICLE{Panichello2021,
  title    = "Shared mechanisms underlie the control of working memory and
              attention",
  author   = "Panichello, Matthew F and Buschman, Timothy J",
  abstract = "Cognitive control guides behaviour by controlling what, when, and
              how information is represented in the brain1. For example,
              attention controls sensory processing; top-down signals from
              prefrontal and parietal cortex strengthen the representation of
              task-relevant stimuli2-4. A similar 'selection' mechanism is
              thought to control the representations held 'in mind'-in working
              memory5-10. Here we show that shared neural mechanisms underlie
              the selection of items from working memory and attention to
              sensory stimuli. We trained rhesus monkeys to switch between two
              tasks, either selecting one item from a set of items held in
              working memory or attending to one stimulus from a set of visual
              stimuli. Neural recordings showed that similar representations in
              prefrontal cortex encoded the control of both selection and
              attention, suggesting that prefrontal cortex acts as a
              domain-general controller. By contrast, both attention and
              selection were represented independently in parietal and visual
              cortex. Both selection and attention facilitated behaviour by
              enhancing and transforming the representation of the selected
              memory or attended stimulus. Specifically, during the selection
              task, memory items were initially represented in independent
              subspaces of neural activity in prefrontal cortex. Selecting an
              item caused its representation to transform from its own subspace
              to a new subspace used to guide behaviour. A similar
              transformation occurred for attention. Our results suggest that
              prefrontal cortex controls cognition by dynamically transforming
              representations to control what and when cognitive computations
              are engaged.",
  journal  = "Nature",
  volume   =  592,
  number   =  7855,
  pages    = "601--605",
  month    =  apr,
  year     =  2021,
  language = "en"
}

@article{Bondanelli2021,
  title={Network dynamics underlying OFF responses in the auditory cortex},
  author={Bondanelli, Giulio and Deneux, Thomas and Bathellier, Brice and Ostojic, Srdjan},
  journal={Elife},
  volume={10},
  pages={e53151},
  year={2021},
  publisher={eLife Sciences Publications Limited}
}

@ARTICLE{Reinert2021-sb,
  title    = "Mouse prefrontal cortex represents learned rules for
              categorization",
  author   = "Reinert, Sandra and H{\"u}bener, Mark and Bonhoeffer, Tobias and
              Goltstein, Pieter M",
  abstract = "The ability to categorize sensory stimuli is crucial for an
              animal's survival in a complex environment. Memorizing categories
              instead of individual exemplars enables greater behavioural
              flexibility and is computationally advantageous. Neurons that
              show category selectivity have been found in several areas of the
              mammalian neocortex1-4, but the prefrontal cortex seems to have a
              prominent role4,5 in this context. Specifically, in primates that
              are extensively trained on a categorization task, neurons in the
              prefrontal cortex rapidly and flexibly represent learned
              categories6,7. However, how these representations first emerge in
              naive animals remains unexplored, leaving it unclear whether
              flexible representations are gradually built up as part of
              semantic memory or assigned more or less instantly during task
              execution8,9. Here we investigate the formation of a neuronal
              category representation throughout the entire learning process by
              repeatedly imaging individual cells in the mouse medial
              prefrontal cortex. We show that mice readily learn rule-based
              categorization and generalize to novel stimuli. Over the course
              of learning, neurons in the prefrontal cortex display distinct
              dynamics in acquiring category selectivity and are differentially
              engaged during a later switch in rules. A subset of neurons
              selectively and uniquely respond to categories and reflect
              generalization behaviour. Thus, a category representation in the
              mouse prefrontal cortex is gradually acquired during learning
              rather than recruited ad hoc. This gradual process suggests that
              neurons in the medial prefrontal cortex are part of a specific
              semantic memory for visual categories.",
  journal  = "Nature",
  volume   =  593,
  number   =  7859,
  pages    = "411--417",
  month    =  may,
  year     =  2021,
  language = "en"
}

@ARTICLE{Halassa2017-ia,
  title    = "Thalamic functions in distributed cognitive control",
  author   = "Halassa, Michael M and Kastner, Sabine",
  abstract = "Cognition can be conceptualized as a set of algorithmic control
              functions whose real-time deployment determines how an organism
              stores and uses information to guide thought and action. A subset
              of these functions is required for goal-directed selection and
              amplification of sensory signals-broadly referred to as
              attention-and for its flexible control and its interaction with
              processes such as working memory and decision making. While the
              contribution of recurrent cortical microcircuits to cognition has
              been extensively studied, the role of the thalamus is just
              beginning to be elucidated. Here we highlight recent studies
              across rodents and primates showing how thalamus contributes to
              attentional control. In addition to high-fidelity information
              relay to or between cortical regions, thalamic circuits shift and
              sustain functional interactions within and across cortical areas.
              This thalamic process enables rapid coordination of spatially
              segregated cortical computations, thereby constructing
              task-relevant functional networks. Because such function may be
              critical for cognitive flexibility, clarifying its mechanisms
              will likely expand our basic understanding of cognitive control
              and its perturbation in disease.",
  journal  = "Nat. Neurosci.",
  volume   =  20,
  number   =  12,
  pages    = "1669--1679",
  month    =  dec,
  year     =  2017,
  keywords = "context-dependent",
  language = "en"
}

@ARTICLE{Ruff2019-xv,
  title    = "Simultaneous multi-area recordings suggest that attention
              improves performance by reshaping stimulus representations",
  author   = "Ruff, Douglas A and Cohen, Marlene R",
  abstract = "Visual attention dramatically improves individuals' ability to
              see and modulates the responses of neurons in every known visual
              and oculomotor area, but whether such modulations can account for
              perceptual improvements is unclear. We measured the relationship
              between populations of visual neurons, oculomotor neurons and
              behavior during detection and discrimination tasks. We found that
              neither of the two prominent hypothesized neuronal mechanisms
              underlying attention (which concern changes in information coding
              and the way sensory information is read out) provide a satisfying
              account of the observed behavioral improvements. Instead, our
              results are more consistent with the hypothesis that attention
              reshapes the representation of attended stimuli to more
              effectively influence behavior. Our results suggest a path toward
              understanding the neural underpinnings of perception and
              cognition in health and disease by analyzing neuronal responses
              in ways that are constrained by behavior and interactions between
              brain areas.",
  journal  = "Nat. Neurosci.",
  volume   =  22,
  number   =  10,
  pages    = "1669--1676",
  month    =  oct,
  year     =  2019,
  keywords = "Multi-area communication",
  language = "en"
}

@ARTICLE{Sani2021-kn,
  title    = "Modeling behaviorally relevant neural dynamics enabled by
              preferential subspace identification",
  author   = "Sani, Omid G and Abbaspourazad, Hamidreza and Wong, Yan T and
              Pesaran, Bijan and Shanechi, Maryam M",
  abstract = "Neural activity exhibits complex dynamics related to various
              brain functions, internal states and behaviors. Understanding how
              neural dynamics explain specific measured behaviors requires
              dissociating behaviorally relevant and irrelevant dynamics, which
              is not achieved with current neural dynamic models as they are
              learned without considering behavior. We develop preferential
              subspace identification (PSID), which is an algorithm that models
              neural activity while dissociating and prioritizing its
              behaviorally relevant dynamics. Modeling data in two monkeys
              performing three-dimensional reach and grasp tasks, PSID revealed
              that the behaviorally relevant dynamics are significantly
              lower-dimensional than otherwise implied. Moreover, PSID
              discovered distinct rotational dynamics that were more predictive
              of behavior. Furthermore, PSID more accurately learned
              behaviorally relevant dynamics for each joint and recording
              channel. Finally, modeling data in two monkeys performing
              saccades demonstrated the generalization of PSID across
              behaviors, brain regions and neural signal types. PSID provides a
              general new tool to reveal behaviorally relevant neural dynamics
              that can otherwise go unnoticed.",
  journal  = "Nat. Neurosci.",
  volume   =  24,
  number   =  1,
  pages    = "140--149",
  month    =  jan,
  year     =  2021,
  language = "en"
}

@ARTICLE{Aoi2020,
  title    = "Prefrontal cortex exhibits multidimensional dynamic encoding
              during decision-making",
  author   = "Aoi, Mikio C and Mante, Valerio and Pillow, Jonathan W",
  abstract = "Recent work has suggested that the prefrontal cortex (PFC) plays
              a key role in context-dependent perceptual decision-making. In
              this study, we addressed that role using a new method for
              identifying task-relevant dimensions of neural population
              activity. Specifically, we show that the PFC has a
              multidimensional code for context, decisions and both relevant
              and irrelevant sensory information. Moreover, these
              representations evolve in time, with an early linear accumulation
              phase followed by a phase with rotational dynamics. We identify
              the dimensions of neural activity associated with these phases
              and show that they do not arise from distinct populations but
              from a single population with broad tuning characteristics.
              Finally, we use model-based decoding to show that the transition
              from linear to rotational dynamics coincides with a plateau in
              decoding accuracy, revealing that rotational dynamics in the PFC
              preserve sensory choice information for the duration of the
              stimulus integration period.",
  journal  = "Nat. Neurosci.",
  volume   =  23,
  number   =  11,
  pages    = "1410--1420",
  month    =  nov,
  year     =  2020,
  language = "en"
}

@ARTICLE{Brincat2018,
  title    = "Gradual progression from sensory to task-related processing in
              cerebral cortex",
  author   = "Brincat, Scott L and Siegel, Markus and von Nicolai, Constantin
              and Miller, Earl K",
  abstract = "Somewhere along the cortical hierarchy, behaviorally relevant
              information is distilled from raw sensory inputs. We examined how
              this transformation progresses along multiple levels of the
              hierarchy by comparing neural representations in visual,
              temporal, parietal, and frontal cortices in monkeys categorizing
              across three visual domains (shape, motion direction, and color).
              Representations in visual areas middle temporal (MT) and V4 were
              tightly linked to external sensory inputs. In contrast, lateral
              prefrontal cortex (PFC) largely represented the abstracted
              behavioral relevance of stimuli (task rule, motion category, and
              color category). Intermediate-level areas, including posterior
              inferotemporal (PIT), lateral intraparietal (LIP), and frontal
              eye fields (FEF), exhibited mixed representations. While the
              distribution of sensory information across areas aligned well
              with classical functional divisions (MT carried stronger motion
              information, and V4 and PIT carried stronger color and shape
              information), categorical abstraction did not, suggesting these
              areas may participate in different networks for stimulus-driven
              and cognitive functions. Paralleling these representational
              differences, the dimensionality of neural population activity
              decreased progressively from sensory to intermediate to frontal
              cortex. This shows how raw sensory representations are
              transformed into behaviorally relevant abstractions and suggests
              that the dimensionality of neural activity in higher cortical
              regions may be specific to their current task.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  115,
  number   =  30,
  pages    = "E7202--E7211",
  month    =  jul,
  year     =  2018,
  keywords = "categorization; cognition; dimensionality; posterior parietal
              cortex; prefrontal cortex;context-dependent",
  language = "en"
}

@ARTICLE{Sejnowski2020-pc,
  title    = "The unreasonable effectiveness of deep learning in artificial
              intelligence",
  author   = "Sejnowski, Terrence J",
  abstract = "Deep learning networks have been trained to recognize speech,
              caption photographs, and translate text between languages at high
              levels of performance. Although applications of deep learning
              networks to real-world problems have become ubiquitous, our
              understanding of why they are so effective is lacking. These
              empirical results should not be possible according to sample
              complexity in statistics and nonconvex optimization theory.
              However, paradoxes in the training and effectiveness of deep
              learning networks are being investigated and insights are being
              found in the geometry of high-dimensional spaces. A mathematical
              theory of deep learning would illuminate how they function, allow
              us to assess the strengths and weaknesses of different network
              architectures, and lead to major improvements. Deep learning has
              provided natural ways for humans to communicate with digital
              devices and is foundational for building artificial general
              intelligence. Deep learning was inspired by the architecture of
              the cerebral cortex and insights into autonomy and general
              intelligence may be found in other brain regions that are
              essential for planning and survival, but major breakthroughs will
              be needed to achieve these goals.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  48,
  pages    = "30033--30038",
  month    =  dec,
  year     =  2020,
  keywords = "artificial intelligence; deep learning; neural networks",
  language = "en"
}

@ARTICLE{Ruff2020-hs,
  title    = "Low rank mechanisms underlying flexible visual representations",
  author   = "Ruff, Douglas A and Xue, Cheng and Kramer, Lily E and Baqai,
              Faisal and Cohen, Marlene R",
  abstract = "Neuronal population responses to sensory stimuli are remarkably
              flexible. The responses of neurons in visual cortex have
              heterogeneous dependence on stimulus properties (e.g., contrast),
              processes that affect all stages of visual processing (e.g.,
              adaptation), and cognitive processes (e.g., attention or task
              switching). Understanding whether these processes affect similar
              neuronal populations and whether they have similar effects on
              entire populations can provide insight into whether they utilize
              analogous mechanisms. In particular, it has recently been
              demonstrated that attention has low rank effects on the
              covariability of populations of visual neurons, which impacts
              perception and strongly constrains mechanistic models. We
              hypothesized that measuring changes in population covariability
              associated with other sensory and cognitive processes could
              clarify whether they utilize similar mechanisms or computations.
              Our experimental design included measurements in multiple visual
              areas using four distinct sensory and cognitive processes. We
              found that contrast, adaptation, attention, and task switching
              affect the variability of responses of populations of neurons in
              primate visual cortex in a similarly low rank way. These results
              suggest that a given circuit may use similar mechanisms to
              perform many forms of modulation and likely reflects a general
              principle that applies to a wide range of brain areas and
              sensory, cognitive, and motor processes.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  47,
  pages    = "29321--29329",
  month    =  nov,
  year     =  2020,
  keywords = "dimensionality; normalization; variability; visual
              cortex;context-dependent",
  language = "en"
}

@ARTICLE{Gutnisky2017-us,
  title    = "Spontaneous Fluctuations in Visual Cortical Responses Influence
              Population Coding Accuracy",
  author   = "Gutnisky, Diego A and Beaman, Charles B and Lew, Sergio E and
              Dragoi, Valentin",
  abstract = "Information processing in the cerebral cortex depends not only on
              the nature of incoming stimuli, but also on the state of neuronal
              networks at the time of stimulation. That is, the same stimulus
              will be processed differently depending on the neuronal context
              in which it is received. A major factor that could influence
              neuronal context is the background, or ongoing neuronal activity
              before stimulation. In visual cortex, ongoing activity is known
              to play a critical role in the development of local circuits, yet
              whether it influences the coding of visual features in adult
              cortex is unclear. Here, we investigate whether and how the
              information encoded by individual neurons and populations in
              primary visual cortex (V1) depends on the ongoing activity before
              stimulus presentation. We report that when individual neurons are
              in a ``low'' prestimulus state, they have a higher capacity to
              discriminate stimulus features, such as orientation, despite
              their reduction in evoked responses. By measuring the
              distribution of prestimulus activity across a population of
              neurons, we found that network discrimination accuracy is
              improved in the low prestimulus state. Thus, the distribution of
              ongoing activity states across the network creates an ``internal
              context'' that dynamically filters incoming stimuli to modulate
              the accuracy of sensory coding. The modulation of stimulus coding
              by ongoing activity state is consistent with recurrent network
              models in which ongoing activity dynamically controls the
              balanced background excitation and inhibition to individual
              neurons.",
  journal  = "Cereb. Cortex",
  volume   =  27,
  number   =  2,
  pages    = "1409--1427",
  month    =  feb,
  year     =  2017,
  keywords = "correlations; networks; spontaneous; visual cortex;saturating
              non-linearities",
  language = "en"
}

@ARTICLE{Cisek2022-wz,
  title    = "Neuroscience needs evolution",
  author   = "Cisek, Paul and Hayden, Benjamin Y",
  abstract = "The nervous system is a product of evolution. That is, it was
              constructed through a long series of modifications, within the
              strong constraints of heredity, and continuously subjected to
              intense selection pressures. As a result, the organization and
              functions of the brain are shaped by its history. We believe that
              this fact, underappreciated in contemporary systems neuroscience,
              offers an invaluable aid for helping us resolve the brain's
              mysteries. Indeed, we think that the consideration of
              evolutionary history ought to take its place alongside other
              intellectual tools used to understand the brain, such as
              behavioural experiments, studies of anatomical structure and
              functional characterization based on recordings of neural
              activity. In this introduction, we argue for the importance of
              evolution by highlighting specific examples of ways that
              evolutionary theory can enhance neuroscience. The rest of the
              theme issue elaborates this point, emphasizing the conservative
              nature of neural evolution, the important consequences of
              specific transitions that occurred in our history, and the ways
              in which considerations of evolution can shed light on issues
              ranging from specific mechanisms to fundamental principles of
              brain organization. This article is part of the theme issue
              'Systems neuroscience through the lens of evolutionary theory'.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  377,
  number   =  1844,
  pages    = "20200518",
  month    =  feb,
  year     =  2022,
  keywords = "developmental neuroscience; evolutionary neuroscience; ontology;
              phylogenetic history; psychology;evolution",
  language = "en"
}

@UNPUBLISHED{Lam2017-rs,
  title    = "Effects of Altered {Excitation-Inhibition} Balance on Decision
              Making in a Cortical Circuit Model",
  author   = "Lam, Norman H and Borduqui, Thiago and Hallak, Jaime and Roque,
              Antonio C and Anticevic, Alan and Krystal, John H and Wang,
              Xiao-Jing and Murray, John D",
  abstract = "Abstract Background Disruption of the synaptic balance between
              excitation and inhibition (E/I balance) in cortical circuits is a
              leading hypothesis for pathophysiologies of neuropsychiatric
              disorders, such as schizophrenia. However, it is poorly
              understood how synaptic E/I disruptions propagate upward to
              induce cognitive deficits, including impaired decision making
              (DM).Methods We investigated how E/I perturbations may impair
              temporal integration of evidence during perceptual DM in a
              biophysically-based model of association cortical microcircuits.
              Using multiple psychophysical task paradigms, we characterized
              effects of NMDA receptor hypofunction at two key synaptic sites:
              inhibitory interneurons (elevating E/I ratio, via disinhibition),
              versus excitatory pyramidal neurons (lowering E/I ratio).Results
              Disruption of E/I balance in either direction can similarly
              impair DM as assessed by psychometric performance, following
              inverted-U dependence. Nonetheless, these regimes make
              dissociable predictions for task paradigms that characterize the
              time course of evidence accumulation. Under elevated E/I ratio,
              DM is impulsive: evidence early in time is weighted much more
              than late evidence. In contrast, under lowered E/I ratio, DM is
              indecisive: evidence integration and winner-take-all competition
              between options are weakened. These effects are well captured by
              an extended drift-diffusion model with self-coupling.Conclusions
              Our findings characterize critical roles of cortical E/I balance
              in cognitive functions, the utility of timing-sensitive
              psychophysical paradigms, and relationships between circuit and
              psychological models. The model makes specific predictions for
              behavior and neural activity that are testable in humans or
              animals under causal manipulations of E/I balance and in disease
              states.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "100347",
  month    =  jan,
  year     =  2017,
  keywords = "Schizofrenia [curr opinion]",
  language = "en"
}

@ARTICLE{Napoli_undated-oi,
  title  = "Correlates of auditory decision making in prefrontal, auditory, and
            basal lateral amygdala cortical areas",
  author = "Napoli, Julia L and Camalier, Corrie R and Brown, Anna Leigh and
            Jacobs, Jessica and Mishkin, Mortimer M and Averbeck, Bruno B"
}

@UNPUBLISHED{Schaeffer2020-tv,
  title    = "Reverse-engineering Recurrent Neural Network solutions to a
              hierarchical inference task for mice",
  author   = "Schaeffer, Rylan and Khona, Mikail and Meshulam, Leenoy and
              {International Brain Laboratory} and Fiete, Ila Rani",
  abstract = "We study how recurrent neural networks (RNNs) solve a
              hierarchical inference task involving two latent variables and
              disparate timescales separated by 1-2 orders of magnitude. The
              task is of interest to the International Brain Laboratory, a
              global collaboration of experimental and theoretical
              neuroscientists studying how the mammalian brain generates
              behavior. We make four discoveries. First, RNNs learn behavior
              that is quantitatively similar to ideal Bayesian baselines.
              Second, RNNs perform inference by learning a two-dimensional
              subspace defining beliefs about the latent variables. Third, the
              geometry of RNN dynamics reflects an induced coupling between the
              two separate inference processes necessary to solve the task.
              Fourth, we perform model compression through a novel form of
              knowledge distillation on hidden representations --
              Representations and Dynamics Distillation (RADD)-- to reduce the
              RNN dynamics to a low-dimensional, highly interpretable model.
              This technique promises a useful tool for interpretability of
              high dimensional nonlinear dynamical systems. Altogether, this
              work yields predictions to guide exploration and analysis of
              mouse neural data and circuity. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.06.09.142745",
  month    =  jun,
  year     =  2020,
  keywords = "Neurips 2020;low-rank",
  language = "en"
}

@UNPUBLISHED{Salvador2020-tr,
  title    = "Premature commitment to uncertain beliefs during human {NMDA}
              receptor hypofunction",
  author   = "Salvador, Alexandre and Arnal, Luc H and Vinckier, Fabien and
              Domenech, Philippe and Gaillard, Rapha{\"e}l and Wyart, Valentin",
  abstract = "In uncertain environments, accurate decision-making requires
              integrating ambiguous or conflicting signals -- a cognitive
              inference process thought to require n-methyl-d-aspartate (NMDA)
              synaptic receptors. Here we characterized the causal impact of
              human NMDA receptor hypofunction on cognitive inference using
              placebo-controlled infusions of ketamine in a visual cue
              combination task. Participants tested under ketamine showed
              elevated uncertainty, together with impaired cognitive inference
              despite intact visual processing. This behavioral effect of
              ketamine was associated in patterns of electrical brain activity
              with degraded and unbalanced coding of presented cues in
              associative cortex, followed by premature response preparation in
              motor cortex. Through quantitative simulations, we propose that
              these cognitive alterations reflect an urge to explain away the
              elevated uncertainty triggered by ketamine. This compensatory
              mechanism may cause the emergence of psychotic symptoms observed
              under chronic NMDA receptor dysfunction, but also forge unusually
              strong beliefs when confronted with uncertainty in everyday life.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.06.17.156539",
  month    =  jun,
  year     =  2020,
  keywords = "Schizofrenia [curr opinion]",
  language = "en"
}


@article{Paszke2017,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@UNPUBLISHED{Cohen2020-tz,
  title    = "Recurrent dynamics of prefrontal cortex during context-dependent
              decision-making",
  author   = "Cohen, Zach and DePasquale, Brian and Aoi, Mikio C and Pillow,
              Jonathan W",
  abstract = "A key problem in systems neuroscience is to understand how neural
              populations integrate relevant sensory inputs during
              decision-making. Here, we address this problem by training a
              structured recurrent neural network to reproduce both
              psychophysical behavior and neural responses recorded from monkey
              prefrontal cortex during a context-dependent perceptual
              decision-making task. Our approach yields a one-to-one mapping of
              model neurons to recorded neurons, and explicitly incorporates
              sensory noise governing the animal's performance as a function of
              stimulus strength. We then analyze the dynamics of the resulting
              model in order to understand how the network computes
              context-dependent decisions. We find that network dynamics
              preserve both relevant and irrelevant stimulus information, and
              exhibit a grid of fixed points for different stimulus conditions
              as opposed to a one-dimensional line attractor. Our work provides
              new insights into context-dependent decision-making and offers a
              powerful framework for linking cognitive function with neural
              activity within an artificial model. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.11.27.401539",
  month    =  nov,
  year     =  2020,
  keywords = "context-dependent",
  language = "en"
}

@article{Semedo2022,
  title={Feedforward and feedback interactions between visual cortical areas use different population activity patterns},
  author={Semedo, Jo{\~a}o D and Jasper, Anna I and Zandvakili, Amin and Krishna, Aravind and Aschner, Amir and Machens, Christian K and Kohn, Adam and Yu, Byron M},
  journal={Nature communications},
  volume={13},
  number={1},
  pages={1--14},
  year={2022},
  publisher={Nature Publishing Group}
}

@ARTICLE{Lundqvist_undated-fg,
  title    = "A {Hot-Coal} theory of Working Memory",
  author   = "Lundqvist, Mikael and Rose, Jonas and Warden, Melissa R and
              Buschman, Tim and Miller, Earl K and Herman, Pawel",
  keywords = "WM"
}



@ARTICLE{Orlandi_undated-is,
  title  = "Distributed context-dependent choice information in mouse
            dorsal-parietal cortex",
  author = "Orlandi, Javier G and Abdolrahmani, Mohammad and Aoki, Ryo and
            Lyamzin, Dmitry and Benucci, Andrea"
}

@UNPUBLISHED{Sorscher2021-bm,
  title    = "The Geometry of Concept Learning",
  author   = "Sorscher, Ben and Ganguli, Surya and Sompolinsky, Haim",
  abstract = "Understanding the neural basis of our remarkable cognitive
              capacity to accurately learn novel high-dimensional naturalistic
              concepts from just one or a few sensory experiences constitutes a
              fundamental problem. We propose a simple, biologically plausible,
              mathematically tractable, and computationally powerful neural
              mechanism for few-shot learning of naturalistic concepts. We
              posit that the concepts we can learn given few examples are
              defined by tightly circumscribed manifolds in the neural firing
              rate space of higher order sensory areas. We further posit that a
              single plastic downstream neuron can learn such concepts from few
              examples using a simple plasticity rule. We demonstrate the
              computational power of our simple proposal by showing it can
              achieve high few-shot learning accuracy on natural visual
              concepts using both macaque inferotemporal cortex representations
              and deep neural network models of these representations, and can
              even learn novel visual concepts specified only through language
              descriptions. Moreover, we develop a mathematical theory of
              few-shot learning that links neurophysiology to behavior by
              delineating several fundamental and measurable geometric
              properties of high-dimensional neural representations that can
              accurately predict the few-shot learning performance of
              naturalistic concepts across all our experiments. We discuss
              several implications of our theory for past and future studies in
              neuroscience, psychology and machine learning. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2021.03.21.436284",
  month    =  mar,
  year     =  2021,
  keywords = "DL vs Brain;high-dimensionality",
  language = "en"
}

@UNPUBLISHED{Srinath2021-gf,
  title    = "Attention improves information flow between neuronal populations
              without changing the communication subspace",
  author   = "Srinath, Ramanujan and Ruff, Douglas A and Cohen, Marlene R",
  abstract = "Visual attention allows observers to flexibly use or ignore
              visual information, suggesting that information can be flexibly
              routed between visual cortex and neurons involved in
              decision-making. We investigated the neural substrate of flexible
              information routing by analyzing the activity of populations of
              visual neurons in the medial temporal area (MT) and oculomotor
              neurons in the superior colliculus (SC) while rhesus monkeys
              switched spatial attention. We demonstrated that attention
              increases the efficacy of visuomotor communication:
              trial-to-trial variability of the population of SC neurons was
              better predicted by the activity of MT neurons (and vice versa)
              when attention was directed toward their joint receptive fields.
              Surprisingly, this improvement in prediction was not explained or
              accompanied by changes in the dimensionality of the shared
              subspace or in local or shared pairwise noise correlations. These
              results suggest a mechanism by which visual attention can affect
              perceptual decision-making without altering local neuronal
              representations. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.03.31.437940",
  month    =  mar,
  year     =  2021,
  language = "en"
}

@article{Maunsell2006,
  title={Feature-based attention in visual cortex},
  author={Maunsell, John HR and Treue, Stefan},
  journal={Trends in neurosciences},
  volume={29},
  number={6},
  pages={317--322},
  year={2006},
  publisher={Elsevier}
}

@UNPUBLISHED{Hajnal2021,
  title    = "Continuous multiplexed population representations of task context
              in the mouse primary visual cortex",
  author   = "Hajnal, M{\'a}rton Albert and Tran, Duy and Einstein, Michael and
              Martelo, Mauricio Vallejo and Safaryan, Karen and Polack,
              Pierre-Olivier and Golshani, Peyman and Orb{\'a}n, Gerg{\H o}",
  abstract = "Primary visual cortex (V1) neurons integrate motor and
              multisensory information with visual inputs during sensory
              processing. However, whether V1 neurons also integrate and encode
              higher-order cognitive variables is less understood. We trained
              mice to perform a context-dependent cross-modal decision task
              where the interpretation of identical audio-visual stimuli
              depends on task context. We performed silicon probe population
              recordings of neuronal activity in V1 during task performance and
              showed that task context (whether the animal should base its
              decision on visual or auditory stimuli) can be decoded during
              both intertrial intervals and stimulus presentations. Context and
              visual stimuli were represented in overlapping populations but
              were orthogonal in the population activity space. Context
              representation was not static but displayed distinctive dynamics
              upon stimulus onset and offset. Thus, activity patterns in V1
              independently represent visual stimuli and cognitive variables
              relevant to task execution. \#\#\# Competing Interest Statement
              The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.04.20.440666",
  month    =  apr,
  year     =  2021,
  keywords = "context-dependent",
  language = "en"
}

@UNPUBLISHED{Flesch2021-py,
  title    = "Rich and lazy learning of task representations in brains and
              neural networks",
  author   = "Flesch, Timo and Juechems, Keno and Dumbalska, Tsvetomira and
              Saxe, Andrew and Summerfield, Christopher",
  abstract = "How do neural populations code for multiple, potentially
              conflicting tasks? Here, we used computational simulations
              involving neural networks to define ``lazy'' and ``rich'' coding
              solutions to this multitasking problem, which trade off learning
              speed for robustness. During lazy learning the input
              dimensionality is expanded by random projections to the network
              hidden layer, whereas in rich learning hidden units acquire
              structured representations that privilege relevant over
              irrelevant features. For context-dependent decision-making, one
              rich solution is to project task representations onto
              low-dimensional and orthogonal manifolds. Using behavioural
              testing and neuroimaging in humans, and analysis of neural
              signals from macaque prefrontal cortex, we report evidence for
              neural coding patterns in biological brains whose dimensionality
              and neural geometry are consistent with the rich learning regime.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.04.23.441128",
  month    =  apr,
  year     =  2021,
  language = "en"
}

@UNPUBLISHED{Curtis2021-ik,
  title    = "Persistent activity during working memory from front to back",
  author   = "Curtis, Clayton E and Sprague, Thomas C",
  abstract = "Working memory (WM) extends the duration over which information
              is available for processing. Given its importance in supporting a
              wide-array of high level cognitive abilities, uncovering the
              neural mechanisms that underlie WM has been a primary goal of
              neuroscience research over the past century. Here, we critically
              review what we consider the two major arcs of inquiry, with a
              specific focus on findings that were theoretically
              transformative. For the first arc, we briefly review classic
              studies that led to the canonical WM theory that cast the
              prefrontal cortex (PFC) as a central player utilizing persistent
              activity of neurons as a mechanism for memory storage. We then
              consider recent challenges to the theory regarding the role of
              persistent neural activity. The second arc, which evolved over
              the last decade, stemmed from sophisticated computational
              neuroimaging approaches enabling researchers to decode the
              contents of WM from the patterns of neural activity in many parts
              of the brain including early visual cortex. We summarize key
              findings from these studies, their implications for WM theory,
              and finally the challenges these findings pose. A comprehensive
              theory of WM will require a unification of these two arcs of
              research. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.04.24.441274",
  month    =  apr,
  year     =  2021,
  keywords = "WM",
  language = "en"
}

@ARTICLE{Tsuda_undated-ox,
  title    = "Neuromodulators enable overlapping synaptic memory regimes and
              nonlinear transition dynamics in recurrent neural networks",
  author   = "Tsuda, Ben and Pate, Stefan C and Tye, Kay M and Siegelmann, Hava
              T and Sejnowski, Terrence J",
  keywords = "RNN"
}

@UNPUBLISHED{Iyer2021-do,
  title    = "Geometry of inter-areal interactions in mouse visual cortex",
  author   = "Iyer, Ramakrishnan and Siegle, Joshua H and Mahalingam, Gayathri
              and Olsen, Shawn and Mihalas, Stefan",
  abstract = "The response of a set of neurons in an area is the result of the
              sensory input, the interaction of the neurons within the area as
              well as the long range interactions between areas. We aimed to
              study the relation between interactions among multiple areas, and
              if they are fixed or dynamic. The structural connectivity
              provides a substrate for these interactions, but anatomical
              connectivity is not known in sufficient detail and it only gives
              us a static picture. Using the Allen Brain Observatory Visual
              Coding Neuropixels dataset, which includes simultaneous
              recordings of spiking activity from up to 6 hierarchically
              organized mouse cortical visual areas, we estimate the functional
              connectivity between neurons using a linear model of responses to
              flashed static grating stimuli. We characterize functional
              connectivity between populations via interaction subspaces. We
              find that distinct subspaces of a source area mediate
              interactions with distinct target areas, supporting the notion
              that cortical areas use distinct channels to communicate. Most
              importantly, using a piecewise linear model for activity within
              each trial, we find that these interactions evolve dynamically
              over tens of milliseconds following a stimulus presentation.
              Inter-areal subspaces become more aligned with the intra-areal
              subspaces during epochs in which a feedforward wave of activity
              propagates through visual cortical areas. When the short-term
              dynamics are averaged over, we find that the interaction
              subspaces are stable over multiple stimulus blocks. These
              findings have important implications for understanding how
              information flows through biological neural networks composed of
              interconnected modules, each of which may have a distinct
              functional specialization. \#\#\# Competing Interest Statement
              The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.06.09.447638",
  month    =  jun,
  year     =  2021,
  keywords = "Multi-area communication",
  language = "en"
}
@article{Javadzadeh2022,
  title={Dynamic causal communication channels between neocortical areas},
  author={Javadzadeh, Mitra and Hofer, Sonja B},
  journal={Neuron},
  year={2022},
  publisher={Elsevier}
}

@article{Carandini2012,
  title={Normalization as a canonical neural computation},
  author={Carandini, Matteo and Heeger, David J},
  journal={Nature Reviews Neuroscience},
  volume={13},
  number={1},
  pages={51--62},
  year={2012},
  publisher={Nature Publishing Group}
}

@UNPUBLISHED{Bimbard2021-ej,
  title    = "Behavioral origin of sound-evoked activity in visual cortex",
  author   = "Bimbard, C{\'e}lian and Sit, Timothy P H and Lebedeva, Anna and
              Harris, Kenneth D and Carandini, Matteo",
  abstract = "Sensory cortices are increasingly thought to encode multisensory
              information. For instance, primary visual cortex (V1) appears to
              be influenced by sounds. Here we show that sound-evoked responses
              in mouse V1 are low-dimensional, similar across neurons and
              across brains, and can be explained by highly stereotyped
              uninstructed movements of eyes and body. Thus, neural activity
              previously interpreted as being sensory or multisensory may have
              a behavioral origin. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.07.01.450721",
  month    =  jul,
  year     =  2021,
  keywords = "high-dimensionality",
  language = "en"
}

@article{Pedregosa2011,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR}
}

@article{Yoo2020,
  title={The transition from evaluation to selection involves neural subspace reorganization in core reward regions},
  author={Yoo, Seng Bum Michael and Hayden, Benjamin Y},
  journal={Neuron},
  volume={105},
  number={4},
  pages={712--724},
  year={2020},
  publisher={Elsevier}
}

@UNPUBLISHED{Fine2021-ah,
  title    = "Subspace alignment as a mechanism for binding",
  author   = "Fine, Justin M and Yoo, Seng Bum Michael and Becket Ebitz, R and
              Hayden, Benjamin Y",
  abstract = "To choose between options, we must solve two important binding
              problems. First, the features that determine each options' values
              must be appropriately combined and kept separate from the
              corresponding features of other options. Second, options must be
              associated with the specific actions needed to select them. We
              hypothesized that the brain solves these problems through use of
              aligned (for bound dimensions) and orthogonal (for separated
              dimensions) population subspaces. We examined responses of single
              neurons in six putative value-coding regions in rhesus macaques
              performing a risky choice task. In all areas, single neurons
              encode the features that define the value of each option (stakes
              and probability) but only very weakly encode value per se .
              However, the coding dimensions associated with these features are
              aligned on a single subspace, from which a strong emergent value
              signal can be read out. Moreover, all six regions use nearly
              orthogonal subspaces for the left and right options, thereby
              linking options to their position in space, implementing
              functional partitioning, and reducing the possibility of
              misbinding. These results provide a new solution to the
              neuroeconomic binding problems and suggest that other forms of
              binding may work through similar principles. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2021.07.07.451472",
  month    =  jul,
  year     =  2021,
  keywords = "low-rank;WM binding",
  language = "en"
}

@ARTICLE{Galgali_undated-xf,
  title    = "Residual dynamics resolves recurrent contributions to neural
              computation",
  author   = "Galgali, Aniruddh R and Sahani, Maneesh and Mante, Valerio",
  keywords = "RNN"
}

@UNPUBLISHED{Jeffrey_Johnston2021-lz,
  title    = "Abstract representations emerge naturally in neural networks
              trained to perform multiple tasks",
  author   = "Jeffrey Johnston, W and Fusi, Stefano",
  abstract = "Humans and other animals demonstrate a remarkable ability to
              generalize knowledge across distinct contexts and objects during
              natural behavior. We posit that this ability depends on the
              geometry of the neural population representations of these
              objects and contexts. Specifically, abstract, or disentangled,
              neural representations -- in which neural population activity is
              a linear function of the variables important for making a
              decision -- are known to allow for this kind of generalization.
              Further, recent neurophysiological studies have shown that the
              brain has sufficiently abstract representations of some sensory
              and cognitive variables to enable generalization across distinct
              contexts. However, it is unknown how these abstract
              representations emerge. Here, using feedforward neural networks,
              we demonstrate a simple mechanism by which these abstract
              representations can be produced: The learning of multiple
              distinct classification tasks. We demonstrate that, despite
              heterogeneity in the task structure, abstract representations
              that enable reliable generalization can be produced from a
              variety of different inputs -- including standard nonlinearly
              mixed inputs, inputs that mimic putative representations from
              early sensory areas, and even simple image inputs from a standard
              machine learning data set. Thus, we conclude that abstract
              representations of sensory and cognitive variables emerge from
              the multiple behaviors that animals exhibit in the natural world,
              and may be pervasive in high-level brain regions. We make several
              specific predictions about which variables will be represented
              abstractly as well as show how these representations can be
              detected. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.10.20.465187",
  month    =  oct,
  year     =  2021,
  language = "en"
}

@UNPUBLISHED{Naumann2021-yp,
  title    = "Invariant neural subspaces maintained by feedback modulation",
  author   = "Naumann, Laura Bella and Keijser, Joram and Sprekeler, Henning",
  abstract = "Sensory systems reliably process incoming stimuli in spite of
              changes in context. Most recent models accredit this context
              invariance to an extraction of increasingly complex sensory
              features in hierarchical feedforward networks. Here, we study how
              context-invariant representations can be established by feedback
              rather than feedforward processing. We show that feedforward
              neural networks modulated by feedback can dynamically generate
              invariant sensory representations. The required feedback can be
              implemented as a slow and spatially diffuse gain modulation. The
              invariance is not present on the level of individual neurons, but
              emerges only on the population level. Mechanistically, the
              feedback modulation dynamically reorients the manifold of neural
              activity and thereby maintains an invariant neural subspace in
              spite of contextual variations. Our results highlight the
              importance of population-level analyses for understanding the
              role of feedback in flexible sensory processing. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2021.10.29.466453",
  month    =  nov,
  year     =  2021,
  keywords = "elife",
  language = "en"
}

@UNPUBLISHED{Gschwend2021-fp,
  title    = "Prefrontal top-down projections control context-dependent
              strategy selection",
  author   = "Gschwend, Olivier and Yang, Tao and van de Lisdonk, Dani{\"e}lle
              and Zhang, Xian and Sharma, Radhashree and Li, Bo",
  abstract = "The rules governing behavior often vary with behavioral contexts.
              As a consequence, an action rewarded in one context may be
              discouraged in another. Animals and humans are capable of
              switching between behavioral strategies under different contexts
              and acting adaptively according to the variable rules, a
              flexibility that is thought to be mediated by the prefrontal
              cortex (PFC)[1][1]--[4][2]. However, how the PFC orchestrates
              context-dependent switch of strategies remains unclear. Here we
              show that pathway-specific projection neurons in the medial PFC
              (mPFC) differentially contribute to context-instructed strategy
              selection. In a decision-making task in which mice have been
              trained to flexibly switch between a previously established rule
              and a newly learned rule in a context-dependent manner, the
              activity of mPFC neurons projecting to the dorsomedial striatum
              encodes the contexts, and further represents decision strategies
              conforming to the old and new rules. Moreover, the activity of
              these neuron is required for context-instructed strategy
              selection. In contrast, the activity of mPFC neurons projecting
              to the ventral midline thalamus does not discriminate between the
              contexts, and represents the old rule even if mice have adopted
              the new one; furthermore, these neurons act to prevent the
              strategy switch under the new rule. Our results suggest that the
              mPFC$\rightarrow$striatum pathway promotes flexible strategy
              selection guided by contexts, whereas the
              mPFC$\rightarrow$thalamus pathway favors fixed strategy selection
              by preserving old rules. Balanced activity between the two
              pathways may be critical for adaptive behaviors. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest. [1]: \#ref-1 [2]: \#ref-4",
  journal  = "bioRxiv",
  pages    = "2021.12.14.472559",
  month    =  dec,
  year     =  2021,
  keywords = "context-dependent",
  language = "en"
}

@UNPUBLISHED{Muscinelli2022-rk,
  title    = "Optimal routing to cerebellum-like structures",
  author   = "Muscinelli, Samuel and Wagner, Mark and Litwin-Kumar, Ashok",
  abstract = "The vast expansion from mossy fibers to cerebellar granule cells
              produces a neural representation that supports functions
              including associative and internal model learning. This motif is
              shared by other cerebellum-like structures, including the insect
              mushroom body, electrosensory lobe of electric fish, and
              mammalian dorsal cochlear nucleus, and has inspired numerous
              theoretical models of its functional role. Less attention has
              been paid to structures immediately presynaptic to granule cell
              layers, whose architecture can be described as a ``bottleneck''
              and whose functional role is not understood. We therefore develop
              a general theory of cerebellum-like structures in conjunction
              with their afferent pathways. This theory predicts the role of
              the pontine relay to cerebellar cortex and the glomerular
              organization of the insect antennal lobe. It also reconciles
              theories of nonlinear mixing with recent observations of
              correlated granule cell activity. More generally, it shows that
              structured compression followed by random expansion is an
              efficient architecture for flexible computation. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2022.02.10.480014",
  month    =  feb,
  year     =  2022,
  keywords = "high-dimensionality ;Multi-area communication",
  language = "en"
}

@UNPUBLISHED{Lundqvist2022-ty,
  title    = "Reduced variability of bursting activity during working memory",
  author   = "Lundqvist, Mikael and Rose, Jonas and Warden, Melissa and
              Buschman, Tim and Herman, Pawel and Miller, Earl",
  abstract = "Working memories have long been thought to be maintained by
              persistent spiking. However, mounting evidence from
              multiple-electrode recording (and single-trial analyses) shows
              that the underlying spiking is better characterized by
              intermittent bursts of activity. A counterargument suggested this
              intermittent activity is at odds with observations that
              spike-time variability reduces during task performance. However,
              this counterargument rests on assumptions, such as randomness in
              the timing of the bursts, that may not be correct. Thus, we
              analyzed spiking and LFPs from the prefrontal cortex (PFC) of
              monkeys to determine if task-related reductions in variability
              can co-exist with intermittent spiking. We found that it does
              because both spiking and associated gamma bursts were
              task-modulated, not random. In fact, the task-related reduction
              in spike variability could be explained by a related reduction in
              gamma burst variability. Our results provide further support for
              the intermittent activity models of working memory as well as
              novel mechanistic insights into how spike variability is reduced
              during cognitive tasks. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.02.18.481088",
  month    =  feb,
  year     =  2022,
  keywords = "WM",
  language = "en"
}

@UNPUBLISHED{Farrell2019-sx,
  title    = "Recurrent neural networks learn robust representations by
              dynamically balancing compression and expansion",
  author   = "Farrell, Matthew and Recanatesi, Stefano and Moore, Timothy and
              Lajoie, Guillaume and Shea-Brown, Eric",
  abstract = "Abstract Recordings of neural circuits in the brain reveal
              extraordinary dynamical richness and high variability. At the
              same time, dimensionality reduction techniques generally uncover
              low-dimensional structures underlying these dynamics. What
              determines the dimensionality of activity in neural circuits?
              What is the functional role of this dimensionality in behavior
              and task learning? In this work we address these questions using
              recurrent neural network (RNN) models, which have recently shown
              promise in predicting and explaining brain dynamics. Through
              simulations and mathematical analysis, we show how the
              dimensionality of RNN activity evolves over time and over stages
              of learning. We find that RNNs can learn to balance tendencies to
              expand and compress dimensionality in a way that matches task
              demands and further generalizes to new data. Strongly chaotic
              networks appear particularly adept in learning this balance in
              the case of classifying low-dimensional inputs, combining the
              natural tendency of chaos to expand dimensionality with
              opportunistic compression driven by stochastic gradient descent
              to form representations with good generalization properties.
              These findings shed light on fundamental dynamical mechanisms by
              which neural networks solve tasks with robust representations
              that generalize to new cases.",
  journal  = "bioRxiv",
  pages    = "564476",
  month    =  dec,
  year     =  2019,
  keywords = "high-dimensionality",
  language = "en"
}

@MISC{Mejias_undated-iu,
  title    = "Mechanisms of distributed working memory in a large-scale network
              of macaque neocortex",
  author   = "Mejias, Jorge F and Wang, Xiao-Jing",
  keywords = "Reviewer;elife"
}

@UNPUBLISHED{Kleinman2020-ds,
  title    = "Recurrent neural network models of multi-area computation
              underlying decision-making",
  author   = "Kleinman, Michael and Chandrasekaran, Chandramouli and Kao,
              Jonathan C",
  abstract = "Cognition emerges from coordinated computations across multiple
              brain areas. However, elucidating these computations within and
              across brain regions is challenging because intra- and inter-area
              connectivity are typically unknown. To study coordinated
              computation, we trained multi-area recurrent neural networks
              (RNNs) to discriminate the dominant color of a checker-board and
              output decision variables reflecting a direction decision, a task
              previously used to investigate decision-related dynamics in
              dorsal premotor cortex (PMd) of monkeys. We found that multi-area
              RNNs, trained with neurophysiological connectivity constraints
              and Dale's law, recapitulated decision-related dynamics observed
              in PMd. The RNN solved this task by a dynamical mechanism where
              the direction decision was computed and outputted, via precisely
              oriented dynamics, on an axis that was nearly orthogonal to
              checkerboard color inputs. This orthogonal direction information
              was preferentially propagated through alignment with inter-area
              connections; in contrast, color information was filtered. These
              results suggest that cortex uses modular computation to generate
              minimal sufficient representations of task information. Finally,
              we used multi-area RNNs to produce experimentally testable
              hypotheses for computations that occur within and across multiple
              brain areas, enabling new insights into distributed computation
              in neural systems. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "798553",
  month    =  nov,
  year     =  2020,
  keywords = "Multi-area communication",
  language = "en"
}

@ARTICLE{Schneegans2019-oc,
  title    = "New perspectives on binding in visual working memory",
  author   = "Schneegans, Sebastian and Bays, Paul M",
  abstract = "How does visual working memory (WM) store the binding between
              different features of a visual object (like colour, orientation,
              and location), and does memorizing these bindings require
              additional resources beyond memorizing individual features? These
              questions have traditionally been addressed by comparing
              performance across different types of change detection task. More
              recently, experimental tasks such as analogue (cued) recall,
              combined with analysis methods including Bayesian hypothesis
              testing and formal model comparison, have shed new light on the
              properties of WM. A significant new perspective is that noise in
              neural representation limits the precision of recall, and several
              recent models incorporate this view to account for failures of
              binding in WM. We review the literature on feature binding with a
              focus on these new developments and discuss their implications
              for the interpretation of classical findings.",
  journal  = "Br. J. Psychol.",
  volume   =  110,
  number   =  2,
  pages    = "207--244",
  month    =  may,
  year     =  2019,
  keywords = "binding; change detection; computational modeling; continuous
              report; cued recall; short-term memory; visual working memory;WM
              binding",
  language = "en"
}

@article{Sussillo2015,
  title={A neural network that finds a naturalistic solution for the production of muscle activity},
  author={Sussillo, David and Churchland, Mark M and Kaufman, Matthew T and Shenoy, Krishna V},
  journal={Nature neuroscience},
  volume={18},
  number={7},
  pages={1025--1033},
  year={2015},
  publisher={Nature Publishing Group}
}

@ARTICLE{Siegel2015,
  title    = "Cortical information flow during flexible sensorimotor decisions",
  author   = "Siegel, Markus and Buschman, Timothy J and Miller, Earl K",
  abstract = "During flexible behavior, multiple brain regions encode sensory
              inputs, the current task, and choices. It remains unclear how
              these signals evolve. We simultaneously recorded neuronal
              activity from six cortical regions [middle temporal area (MT),
              visual area four (V4), inferior temporal cortex (IT), lateral
              intraparietal area (LIP), prefrontal cortex (PFC), and frontal
              eye fields (FEF)] of monkeys reporting the color or motion of
              stimuli. After a transient bottom-up sweep, there was a top-down
              flow of sustained task information from frontoparietal to visual
              cortex. Sensory information flowed from visual to parietal and
              prefrontal cortex. Choice signals developed simultaneously in
              frontoparietal regions and travelled to FEF and sensory cortex.
              This suggests that flexible sensorimotor choices emerge in a
              frontoparietal network from the integration of opposite flows of
              sensory and task information.",
  journal  = "Science",
  volume   =  348,
  number   =  6241,
  pages    = "1352--1355",
  month    =  jun,
  year     =  2015,
  keywords = "context-dependent",
  language = "en"
}

@article{Thivierge2022,
  title={Estimating null and potent modes of feedforward communication in a computational model of cortical activity},
  author={Thivierge, Jean-Philippe and Pilzak, Artem},
  journal={Scientific Reports},
  volume={12},
  number={1},
  pages={1--12},
  year={2022},
  publisher={Nature Publishing Group}
}

@ARTICLE{Ni2018-bn,
  title    = "Learning and attention reveal a general relationship between
              population activity and behavior",
  author   = "Ni, A M and Ruff, D A and Alberts, J J and Symmonds, J and Cohen,
              M R",
  abstract = "Prior studies have demonstrated that correlated variability
              changes with cognitive processes that improve perceptual
              performance. We tested whether correlated variability covaries
              with subjects' performance-whether performance improves quickly
              with attention or slowly with perceptual learning. We found a
              single, consistent relationship between correlated variability
              and behavioral performance, regardless of the time frame of
              correlated variability change. This correlated variability was
              oriented along the dimensions in population space used by the
              animal on a trial-by-trial basis to make decisions. That
              subjects' choices were predicted by specific dimensions that were
              aligned with the correlated variability axis clarifies
              long-standing paradoxes about the relationship between shared
              variability and behavior.",
  journal  = "Science",
  volume   =  359,
  number   =  6374,
  pages    = "463--465",
  month    =  jan,
  year     =  2018,
  language = "en"
}

@ARTICLE{Luo2021-ge,
  title     = "Architectures of neuronal circuits",
  author    = "Luo, Liqun",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  373,
  number    =  6559,
  month     =  sep,
  year      =  2021,
  keywords  = "evolution",
  language  = "en"
}

@ARTICLE{Thompson2021-rk,
  title     = "Forms of explanation and understanding for neuroscience and
               artificial intelligence",
  author    = "Thompson, Jessica A F",
  abstract  = "Much of the controversy evoked by the use of deep neural
               networks as models of biological neural systems amount to
               debates over what constitutes scientific progress in
               neuroscience. To discuss what constitutes scientific progress,
               one must have a goal in mind (progress toward what?). One such
               long-term goal is to produce scientific explanations of
               intelligent capacities (e.g., object recognition, relational
               reasoning). I argue that the most pressing philosophical
               questions at the intersection of neuroscience and artificial
               intelligence are ultimately concerned with defining the
               phenomena to be explained and with what constitute valid
               explanations of such phenomena. I propose that a foundation in
               the philosophy of scientific explanation and understanding can
               scaffold future discussions about how an integrated science of
               intelligence might progress. Toward this vision, I review
               relevant theories of scientific explanation and discuss
               strategies for unifying the scientific goals of neuroscience and
               AI.",
  journal   = "J. Neurophysiol.",
  publisher = "American Physiological Society",
  volume    =  126,
  number    =  6,
  pages     = "1860--1874",
  month     =  dec,
  year      =  2021,
  keywords  = "causality; deep learning; explanation; intelligibility;
               understanding;DL vs Brain",
  language  = "en"
}

@ARTICLE{Meyers2008,
  title    = "Dynamic population coding of category information in inferior
              temporal and prefrontal cortex",
  author   = "Meyers, Ethan M and Freedman, David J and Kreiman, Gabriel and
              Miller, Earl K and Poggio, Tomaso",
  abstract = "Most electrophysiology studies analyze the activity of each
              neuron separately. While such studies have given much insight
              into properties of the visual system, they have also potentially
              overlooked important aspects of information coded in changing
              patterns of activity that are distributed over larger populations
              of neurons. In this work, we apply a population decoding method
              to better estimate what information is available in neuronal
              ensembles and how this information is coded in dynamic patterns
              of neural activity in data recorded from inferior temporal cortex
              (ITC) and prefrontal cortex (PFC) as macaque monkeys engaged in a
              delayed match-to-category task. Analyses of activity patterns in
              ITC and PFC revealed that both areas contain ``abstract''
              category information (i.e., category information that is not
              directly correlated with properties of the stimuli); however, in
              general, PFC has more task-relevant information, and ITC has more
              detailed visual information. Analyses examining how information
              coded in these areas show that almost all category information is
              available in a small fraction of the neurons in the population.
              Most remarkably, our results also show that category information
              is coded by a nonstationary pattern of activity that changes over
              the course of a trial with individual neurons containing
              information on much shorter time scales than the population as a
              whole.",
  journal  = "J. Neurophysiol.",
  volume   =  100,
  number   =  3,
  pages    = "1407--1419",
  month    =  sep,
  year     =  2008,
  language = "en"
}

@ARTICLE{Roweis1999-kr,
  title    = "A unifying review of linear gaussian models",
  author   = "Roweis, S and Ghahramani, Z",
  abstract = "Factor analysis, principal component analysis, mixtures of
              gaussian clusters, vector quantization, Kalman filter models, and
              hidden Markov models can all be unified as variations of
              unsupervised learning under a single basic generative model. This
              is achieved by collecting together disparate observations and
              derivations made by many previous authors and introducing a new
              way of linking discrete and continuous state models using a
              simple nonlinearity. Through the use of other nonlinearities, we
              show how independent component analysis is also a variation of
              the same basic generative model. We show that factor analysis and
              mixtures of gaussians can be implemented in autoencoder neural
              networks and learned using squared error plus the same
              regularization term. We introduce a new model for static data,
              known as sensible principal component analysis, as well as a
              novel concept of spatially adaptive observation noise. We also
              review some of the literature involving global and local mixtures
              of the basic models and provide pseudocode for inference and
              learning for all the basic models.",
  journal  = "Neural Comput.",
  volume   =  11,
  number   =  2,
  pages    = "305--345",
  month    =  feb,
  year     =  1999,
  keywords = "low-rank",
  language = "en"
}

@ARTICLE{Zenke2021-lu,
  title    = "The Remarkable Robustness of Surrogate Gradient Learning for
              Instilling Complex Function in Spiking Neural Networks",
  author   = "Zenke, Friedemann and Vogels, Tim P",
  abstract = "Brains process information in spiking neural networks. Their
              intricate connections shape the diverse functions these networks
              perform. Yet how network connectivity relates to function is
              poorly understood, and the functional capabilities of models of
              spiking networks are still rudimentary. The lack of both
              theoretical insight and practical algorithms to find the
              necessary connectivity poses a major impediment to both studying
              information processing in the brain and building efficient
              neuromorphic hardware systems. The training algorithms that solve
              this problem for artificial neural networks typically rely on
              gradient descent. But doing so in spiking networks has remained
              challenging due to the nondifferentiable nonlinearity of spikes.
              To avoid this issue, one can employ surrogate gradients to
              discover the required connectivity. However, the choice of a
              surrogate is not unique, raising the question of how its
              implementation influences the effectiveness of the method. Here,
              we use numerical simulations to systematically study how
              essential design parameters of surrogate gradients affect
              learning performance on a range of classification problems. We
              show that surrogate gradient learning is robust to different
              shapes of underlying surrogate derivatives, but the choice of the
              derivative's scale can substantially affect learning performance.
              When we combine surrogate gradients with suitable activity
              regularization techniques, spiking networks perform robust
              information processing at the sparse activity limit. Our study
              provides a systematic account of the remarkable robustness of
              surrogate gradient learning and serves as a practical guide to
              model functional spiking neural networks.",
  journal  = "Neural Comput.",
  pages    = "1--27",
  month    =  jan,
  year     =  2021,
  language = "en"
}

@ARTICLE{Beiran2021,
  title    = "Shaping Dynamics With Multiple Populations in {Low-Rank}
              Recurrent Networks",
  author   = "Beiran, Manuel and Dubreuil, Alexis and Valente, Adrian and
              Mastrogiuseppe, Francesca and Ostojic, Srdjan",
  abstract = "An emerging paradigm proposes that neural computations can be
              understood at the level of dynamic systems that govern
              low-dimensional trajectories of collective neural activity. How
              the connectivity structure of a network determines the emergent
              dynamical system, however, remains to be clarified. Here we
              consider a novel class of models, gaussian-mixture, low-rank
              recurrent networks in which the rank of the connectivity matrix
              and the number of statistically defined populations are
              independent hyperparameters. We show that the resulting
              collective dynamics form a dynamical system, where the rank sets
              the dimensionality and the population structure shapes the
              dynamics. In particular, the collective dynamics can be described
              in terms of a simplified effective circuit of interacting latent
              variables. While having a single global population strongly
              restricts the possible dynamics, we demonstrate that if the
              number of populations is large enough, a rank R network can
              approximate any R-dimensional dynamical system.",
  journal  = "Neural Comput.",
  volume   =  33,
  number   =  6,
  pages    = "1572--1615",
  month    =  may,
  year     =  2021,
  language = "en"
}

@article{Dubreuil2022,
  title={The role of population structure in computations through neural dynamics},
  author={Dubreuil, Alexis and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  journal={Nature Neuroscience},
  pages={1--12},
  year={2022},
  publisher={Nature Publishing Group}
}

@ARTICLE{Rajakumar2021-qu,
  title    = "{Stimulus-Driven} and Spontaneous Dynamics in
              {Excitatory-Inhibitory} Recurrent Neural Networks for Sequence
              Representation",
  author   = "Rajakumar, Alfred and Rinzel, John and Chen, Zhe S",
  abstract = "Recurrent neural networks (RNNs) have been widely used to model
              sequential neural dynamics (``neural sequences'') of cortical
              circuits in cognitive and motor tasks. Efforts to incorporate
              biological constraints and Dale's principle will help elucidate
              the neural representations and mechanisms of underlying circuits.
              We trained an excitatory-inhibitory RNN to learn neural sequences
              in a supervised manner and studied the representations and
              dynamic attractors of the trained network. The trained RNN was
              robust to trigger the sequence in response to various input
              signals and interpolated a time-warped input for sequence
              representation. Interestingly, a learned sequence can repeat
              periodically when the RNN evolved beyond the duration of a single
              sequence. The eigenspectrum of the learned recurrent connectivity
              matrix with growing or damping modes, together with the RNN's
              nonlinearity, were adequate to generate a limit cycle attractor.
              We further examined the stability of dynamic attractors while
              training the RNN to learn two sequences. Together, our results
              provide a general framework for understanding neural sequence
              representation in the excitatory-inhibitory RNN.",
  journal  = "Neural Comput.",
  volume   =  33,
  number   =  10,
  pages    = "2603--2645",
  month    =  sep,
  year     =  2021,
  keywords = "RNN",
  language = "en"
}

@ARTICLE{Seeholzer2019-ga,
  title    = "Stability of working memory in continuous attractor networks
              under the control of short-term plasticity",
  author   = "Seeholzer, Alexander and Deger, Moritz and Gerstner, Wulfram",
  abstract = "Continuous attractor models of working-memory store
              continuous-valued information in continuous state-spaces, but are
              sensitive to noise processes that degrade memory retention.
              Short-term synaptic plasticity of recurrent synapses has
              previously been shown to affect continuous attractor systems:
              short-term facilitation can stabilize memory retention, while
              short-term depression possibly increases continuous attractor
              volatility. Here, we present a comprehensive description of the
              combined effect of both short-term facilitation and depression on
              noise-induced memory degradation in one-dimensional continuous
              attractor models. Our theoretical description, applicable to rate
              models as well as spiking networks close to a stationary state,
              accurately describes the slow dynamics of stored memory positions
              as a combination of two processes: (i) diffusion due to
              variability caused by spikes; and (ii) drift due to random
              connectivity and neuronal heterogeneity. We find that
              facilitation decreases both diffusion and directed drifts, while
              short-term depression tends to increase both. Using mutual
              information, we evaluate the combined impact of short-term
              facilitation and depression on the ability of networks to retain
              stable working memory. Finally, our theory predicts the
              sensitivity of continuous working memory to distractor inputs and
              provides conditions for stability of memory.",
  journal  = "PLoS Comput. Biol.",
  volume   =  15,
  number   =  4,
  pages    = "e1006928",
  month    =  apr,
  year     =  2019,
  keywords = "Schizofrenia [curr opinion]",
  language = "en"
}

@ARTICLE{Glaser2020-di,
  title     = "Machine learning for neural decoding",
  author    = "Glaser, Joshua I and Benjamin, Ari S and Chowdhury, Raeed H and
               Perich, Matthew G and Miller, Lee E and Kording, Konrad P",
  abstract  = "Despite rapid advances in machine learning tools, the majority
               of neural decoding approaches still use traditional methods.
               Modern machine learning tools, which are versatile and easy to
               use, have the potential to significantly improve decoding
               performance. This tutorial describes how to effectively apply
               these algorithms for typical decoding problems. We provide
               descriptions, best practices, and code for applying common
               machine learning methods, including neural networks and gradient
               boosting. We also provide detailed comparisons of the
               performance of various methods at the task of decoding spiking
               activity in motor cortex, somatosensory cortex, and hippocampus.
               Modern methods, particularly neural networks and ensembles,
               significantly outperform traditional approaches, such as Wiener
               and Kalman filters. Improving the performance of neural decoding
               algorithms allows neuroscientists to better understand the
               information contained in a neural population and can help to
               advance engineering applications such as brain-machine
               interfaces. Our code package is available at
               github.com/kordinglab/neural\_decoding.",
  journal   = "eNeuro",
  publisher = "Society for Neuroscience",
  volume    =  7,
  number    =  4,
  pages     = "ENEURO.0506--19.2020",
  month     =  aug,
  year      =  2020,
  keywords  = "Deep learning; Hippocampus; Machine learning; Motor cortex;
               Neural data analysis; Neural decoding; Somatosensory cortex",
  language  = "en"
}

@ARTICLE{Glaser2020-gl,
  title     = "Machine learning for neural decoding",
  author    = "Glaser, Joshua I and Benjamin, Ari S and Chowdhury, Raeed H and
               Perich, Matthew G and Miller, Lee E and Kording, Konrad P",
  abstract  = "Despite rapid advances in machine learning tools, the majority
               of neural decoding approaches still use traditional methods.
               Modern machine learning tools, which are versatile and easy to
               use, have the potential to significantly improve decoding
               performance. This tutorial describes how to effectively apply
               these algorithms for typical decoding problems. We provide
               descriptions, best practices, and code for applying common
               machine learning methods, including neural networks and gradient
               boosting. We also provide detailed comparisons of the
               performance of various methods at the task of decoding spiking
               activity in motor cortex, somatosensory cortex, and hippocampus.
               Modern methods, particularly neural networks and ensembles,
               significantly outperform traditional approaches, such as Wiener
               and Kalman filters. Improving the performance of neural decoding
               algorithms allows neuroscientists to better understand the
               information contained in a neural population and can help to
               advance engineering applications such as brain-machine
               interfaces. Our code package is available at
               github.com/kordinglab/neural\_decoding.",
  journal   = "eNeuro",
  publisher = "Society for Neuroscience",
  volume    =  7,
  number    =  4,
  pages     = "ENEURO.0506--19.2020",
  month     =  aug,
  year      =  2020,
  keywords  = "Deep learning; Hippocampus; Machine learning; Motor cortex;
               Neural data analysis; Neural decoding; Somatosensory cortex;ML",
  language  = "en"
}

@article{Hirokawa2019,
  title={Frontal cortex neuron types categorically encode single decision variables},
  author={Hirokawa, Junya and Vaughan, Alexander and Masset, Paul and Ott, Torben and Kepecs, Adam},
  journal={Nature},
  volume={576},
  number={7787},
  pages={446--451},
  year={2019},
  publisher={Nature Publishing Group}
}

@ARTICLE{Uka2012,
  title    = "Change in choice-related response modulation in area {MT} during
              learning of a depth-discrimination task is consistent with task
              learning",
  author   = "Uka, Takanori and Sasaki, Ryo and Kumano, Hironori",
  abstract = "What are the neural mechanisms underlying improvement in
              perceptual performance due to learning? A recent study using
              motion-direction discrimination suggested that perceptual
              learning is due to improvements in the ``readout'' of sensory
              signals in sensory-motor cortex and not to improvements in neural
              sensitivity of the sensory cortex. To test the generality of this
              hypothesis, we examined this in a similar but different task. We
              recorded from isolated neurons in the middle temporal (MT) area
              while monkeys were trained in a depth-discrimination task.
              Consistent with earlier reports using direction discrimination,
              we found no long-term improvement in MT neuron sensitivity to
              depth, although monkey performance improved over months with
              extensive training, even when taking out the effect of behavioral
              biases. We further addressed improvement in the readout of
              sensory signals by focusing on choice-related response modulation
              [choice probability (CP)]. CP increased with training, suggesting
              an improvement in the readout of sensory signals from MT. CP,
              however, correlated more strongly with lapse rate than
              psychophysical threshold, suggesting that changes in readout may
              be restricted to early phases of learning. To test how behavioral
              learning, as well as the magnitude of CP, transferred across
              visual fields, we measured CP variation in one hemifield after
              training monkeys on the depth-discrimination task in the opposite
              hemifield. CP was large from the beginning of training in the
              untrained hemifield, even though a small but significant
              improvement in sensitivity was observed behaviorally. Overall,
              our findings are consistent with the idea that increases in CP
              reflect task learning.",
  journal  = "J. Neurosci.",
  volume   =  32,
  number   =  40,
  pages    = "13689--13700",
  month    =  oct,
  year     =  2012,
  language = "en"
}

@article{Jaramillo2019,
  title={Engagement of pulvino-cortical feedforward and feedback pathways in cognitive computations},
  author={Jaramillo, Jorge and Mejias, Jorge F and Wang, Xiao-Jing},
  journal={Neuron},
  volume={101},
  number={2},
  pages={321--336},
  year={2019},
  publisher={Elsevier}
}

@article{Winkowski2013,
  title={Laminar transformation of frequency organization in auditory cortex},
  author={Winkowski, Daniel E and Kanold, Patrick O},
  journal={Journal of Neuroscience},
  volume={33},
  number={4},
  pages={1498--1508},
  year={2013},
  publisher={Soc Neuroscience}
}

@article{Jercog2021,
  title={Dynamical prefrontal population coding during defensive behaviours},
  author={Jercog, Daniel and Winke, Nanci and Sung, Kibong and Fernandez, Mario Martin and Francioni, Claire and Rajot, Domitille and Courtin, Julien and Chaudun, Fabrice and Jercog, Pablo E and Valerio, Stephane and others},
  journal={Nature},
  volume={595},
  number={7869},
  pages={690--694},
  year={2021},
  publisher={Nature Publishing Group}
}

@UNPUBLISHED{Molano-Mazon2022,
  title    = "{NeuroGym}: An open resource for developing and sharing
              neuroscience tasks",
  author   = "Molano-Mazon, Manuel and Barbosa, Joao and Pastor-Ciurana, Jordi
              and Fradera, Marta and Zhang, Ru-Yuan and Forest, Jeremy and del
              Pozo Lerida, Jorge and Ji-An, Li and Cueva, Christopher J and de
              la Rocha, Jaime and al., Et",
  abstract = "Artificial Neural Networks (ANNs) trained on specific cognitive
              tasks have re-emerged as a useful tool to study the brain.
              However, ANNs would better aid cognitive neuroscience if a given
              network could be easily trained on a wide range of tasks for
              which neural recordings are available. Moreover, unintentional
              divergent implementations of cognitive tasks can produce variable
              results, which limits their interpretability. Towards this goal,
              we present NeuroGym, an open-source Python package that provides
              a large collection of customizable neuroscience tasks to test and
              compare network models. Building upon the OpenAI Gym toolbox,
              NeuroGym tasks (1) are written in a high-level flexible Python
              framework; (2) possess a shared interface tailored to common
              needs of neuroscience tasks that facilitates their design and
              usage; (3) support the training of ANNs using both Reinforcement
              and Supervised Learning techniques. The toolbox allows easy
              assembly of new tasks by modifying existing ones in a
              hierarchical and modular fashion. These design features make it
              straightforward to take a network designed for one task and train
              it on many other tasks. NeuroGym is a community-driven effort
              that contributes to a rapidly evolving open ecosystem of neural
              network development, data analysis, and model-data comparison.",
  month    =  feb,
  year     =  2022,
  keywords = "artificial neural networks; cognition; cognitive neuroscience;
              neuroscience tasks; open-source Python package; reinforcement
              learning; supervised learning; toolbox; training"
}

@UNPUBLISHED{Musslick2020-uu,
  title    = "Rationalizing Constraints on the Capacity for Cognitive Control",
  author   = "Musslick, Sebastian and Cohen, Jonathan D",
  abstract = "Humans are remarkably limited in (a) how many control-dependent
              tasks they can execute simultaneously, and (b) how intensely they
              can focus on a single task. These limitations are universal
              assumptions of most theories of cognition. Yet, a rationale for
              why humans are subject to these constraints remains elusive. This
              review draws on recent insights from psychology, neuroscience and
              machine learning, to suggest that constraints on cognitive
              control may result from a rational adaptation to fundamental
              computational dilemmas in neural architectures. The reviewed
              literature implies that limitations in multitasking may result
              from a tradeoff between learning efficacy and processing
              efficiency, and that limitations in the intensity of commitment
              to a single task may reflect a tradeoff between cognitive
              stability and flexibility.",
  month    =  nov,
  year     =  2020,
  keywords = "information processing limitations; multitasking; task switching;
              visual attention; working memory;Cog sci"
}

@article{Kingma2014,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@ARTICLE{Paneri2017,
  title    = "{Top-Down} Control of Visual Attention by the Prefrontal Cortex.
              Functional Specialization and {Long-Range} Interactions",
  author   = "Paneri, Sofia and Gregoriou, Georgia G",
  abstract = "The ability to select information that is relevant to current
              behavioral goals is the hallmark of voluntary attention and an
              essential part of our cognition. Attention tasks are a prime
              example to study at the neuronal level, how task related
              information can be selectively processed in the brain while
              irrelevant information is filtered out. Whereas, numerous studies
              have focused on elucidating the mechanisms of visual attention at
              the single neuron and population level in the visual cortices,
              considerably less work has been devoted to deciphering the
              distinct contribution of higher-order brain areas, which are
              known to be critical for the employment of attention. Among these
              areas, the prefrontal cortex (PFC) has long been considered a
              source of top-down signals that bias selection in early visual
              areas in favor of the attended features. Here, we review recent
              experimental data that support the role of PFC in attention. We
              examine the existing evidence for functional specialization
              within PFC and we discuss how long-range interactions between PFC
              subregions and posterior visual areas may be implemented in the
              brain and contribute to the attentional modulation of different
              measures of neural activity in visual cortices.",
  journal  = "Front. Neurosci.",
  volume   =  11,
  pages    = "545",
  month    =  sep,
  year     =  2017,
  keywords = "executive control; feature attention; long-range interactions;
              oscillatory synchrony; prefrontal cortex; review; spatial
              attention; visual cortex",
  language = "en"
}

@ARTICLE{Freedman_undated-vi,
  title    = "Distributed functions of prefrontal and parietal cortices during
              sequential categorical decisions",
  author   = "Freedman, David",
  keywords = "Reviewer;elife"
}

@ARTICLE{Kobak2016-eb,
  title    = "Demixed principal component analysis of neural population data",
  author   = "Kobak, Dmitry and Brendel, Wieland and Constantinidis, Christos
              and Feierstein, Claudia E and Kepecs, Adam and Mainen, Zachary F
              and Qi, Xue-Lian and Romo, Ranulfo and Uchida, Naoshige and
              Machens, Christian K",
  abstract = "Neurons in higher cortical areas, such as the prefrontal cortex,
              are often tuned to a variety of sensory and motor variables, and
              are therefore said to display mixed selectivity. This complexity
              of single neuron responses can obscure what information these
              areas represent and how it is represented. Here we demonstrate
              the advantages of a new dimensionality reduction technique,
              demixed principal component analysis (dPCA), that decomposes
              population activity into a few components. In addition to
              systematically capturing the majority of the variance of the
              data, dPCA also exposes the dependence of the neural
              representation on task parameters such as stimuli, decisions, or
              rewards. To illustrate our method we reanalyze population data
              from four datasets comprising different species, different
              cortical areas and different experimental tasks. In each case,
              dPCA provides a concise way of visualizing the data that
              summarizes the task-dependent features of the population response
              in a single figure.",
  journal  = "Elife",
  volume   =  5,
  month    =  apr,
  year     =  2016,
  keywords = "dimensionality reduction; neuroscience; population activity;
              prefrontal cortex; principal component analysis; rat; rhesus
              macaque;low-rank",
  language = "en"
}

@ARTICLE{Sandhaeger2019-fc,
  title    = "Monkey {EEG} links neuronal color and motion information across
              species and scales",
  author   = "Sandhaeger, Florian and von Nicolai, Constantin and Miller, Earl
              K and Siegel, Markus",
  abstract = "It remains challenging to relate EEG and MEG to underlying
              circuit processes and comparable experiments on both spatial
              scales are rare. To close this gap between invasive and
              non-invasive electrophysiology we developed and recorded
              human-comparable EEG in macaque monkeys during visual stimulation
              with colored dynamic random dot patterns. Furthermore, we
              performed simultaneous microelectrode recordings from 6 areas of
              macaque cortex and human MEG. Motion direction and color
              information were accessible in all signals. Tuning of the
              non-invasive signals was similar to V4 and IT, but not to dorsal
              and frontal areas. Thus, MEG and EEG were dominated by early
              visual and ventral stream sources. Source level analysis revealed
              corresponding information and latency gradients across cortex. We
              show how information-based methods and monkey EEG can identify
              analogous properties of visual processing in signals spanning
              spatial scales from single units to MEG - a valuable framework
              for relating human and animal studies.",
  journal  = "Elife",
  volume   =  8,
  month    =  jul,
  year     =  2019,
  keywords = "color vision; decoding; electrophysiology; human; human MEG;
              monkey EEG; motion perception; neuroscience; rhesus
              macaque;context-dependent",
  language = "en"
}

@ARTICLE{Cavanagh2020-pd,
  title    = "A circuit mechanism for decision-making biases and {NMDA}
              receptor hypofunction",
  author   = "Cavanagh, Sean Edward and Lam, Norman H and Murray, John D and
              Hunt, Laurence Tudor and Kennerley, Steven Wayne",
  abstract = "Decision-making biases can be features of normal behaviour, or
              deficits underlying neuropsychiatric symptoms. We used
              behavioural psychophysics, spiking-circuit modelling and
              pharmacological manipulations to explore decision-making biases
              during evidence integration. Monkeys showed a pro-variance bias
              (PVB): a preference to choose options with more variable
              evidence. The PVB was also present in a spiking circuit model,
              revealing a potential neural mechanism for this behaviour. To
              model possible effects of NMDA receptor (NMDA-R) antagonism on
              this behaviour, we simulated the effects of NMDA-R hypofunction
              onto either excitatory or inhibitory neurons in the model. These
              were then tested experimentally using the NMDA-R antagonist
              ketamine, a pharmacological model of schizophrenia. Ketamine
              yielded an increase in subjects' PVB, consistent with lowered
              cortical excitation/inhibition balance from NMDA-R hypofunction
              predominantly onto excitatory neurons. These results provide a
              circuit-level mechanism that bridges across explanatory scales,
              from the synaptic to the behavioural, in neuropsychiatric
              disorders where decision-making biases are prominent.",
  journal  = "Elife",
  volume   =  9,
  month    =  sep,
  year     =  2020,
  keywords = "NMDA receptor; decision-making; ketamine; network model;
              neuroscience; rhesus macaque; schizophrenia;Schizofrenia [curr
              opinion]",
  language = "en"
}

@ARTICLE{Takagi2021-qe,
  title    = "Adapting non-invasive human recordings along multiple task-axes
              shows unfolding of spontaneous and over-trained choice",
  author   = "Takagi, Yu and Hunt, Laurence Tudor and Woolrich, Mark W and
              Behrens, Timothy Ej and Klein-Fl{\"u}gge, Miriam C",
  abstract = "Choices rely on a transformation of sensory inputs into motor
              responses. Using invasive single neuron recordings, the evolution
              of a choice process has been tracked by projecting population
              neural responses into state spaces. Here, we develop an approach
              that allows us to recover similar trajectories on a millisecond
              timescale in non-invasive human recordings. We selectively
              suppress activity related to three task-axes, relevant and
              irrelevant sensory inputs and response direction, in
              magnetoencephalography data acquired during context-dependent
              choices. Recordings from premotor cortex show a progression from
              processing sensory input to processing the response. In contrast
              to previous macaque recordings, information related to
              choice-irrelevant features is represented more weakly than
              choice-relevant sensory information. To test whether this
              mechanistic difference between species is caused by extensive
              over-training common in non-human primate studies, we trained
              humans on >20,000 trials of the task. Choice-irrelevant features
              were still weaker than relevant features in premotor cortex after
              over-training.",
  journal  = "Elife",
  volume   =  10,
  month    =  may,
  year     =  2021,
  keywords = "human; magnetoencephalography; neural population trajectory;
              neuroscience; repetition suppression; top-down
              attention;context-dependent",
  language = "en"
}

@ARTICLE{Ashwood2020-wu,
  title    = "Inferring learning rules from animal decision-making",
  author   = "Ashwood, Zoe and Roy, Nicholas A and Bak, Ji Hyun and Pillow,
              Jonathan W",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  year     =  2020,
  keywords = "Neurips 2020"
}

@ARTICLE{Nayebi2020-ql,
  title   = "Identifying Learning Rules From Neural Network Observables",
  author  = "Nayebi, Aran and Srivastava, Sanjana and Ganguli, Surya and
             Yamins, Daniel L",
  journal = "Adv. Neural Inf. Process. Syst.",
  volume  =  33,
  year    =  2020
}

@ARTICLE{Draft--_undated-gx,
  title    = "Neural evidence for categorical biases in working memory for
              location and orientation",
  author   = "Draft--, --Manuscript",
  keywords = "Reviewer"
}

@ARTICLE{Wolff_undated-mk,
  title    = "1 What is the functional role of delay-related alpha oscillations
              2 during working memory?",
  author   = "Wolff, Michael J and Aky{\"u}rek, Elkan G and Stokes, Mark G",
  keywords = "WM"
}

@ARTICLE{Takagi2020-yy,
  title    = "Demixed shared component analysis of neural population data from
              multiple brain areas",
  author   = "Takagi, Yu and Kennerley, Steven and Hirayama, Jun-Ichiro and
              Hunt, Laurence",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  pages    = "6235--6244",
  year     =  2020,
  keywords = "Multi-area communication"
}

@ARTICLE{Takagi2020-ua,
  title    = "Demixed shared component analysis of neural population data from
              multiple brain areas",
  author   = "Takagi, Yu and Kennerley, Steven and Hirayama, Jun-Ichiro and
              Hunt, Laurence",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  year     =  2020,
  keywords = "methods;Neurips 2020"
}

@ARTICLE{Huang_undated-vi,
  title    = "Modulation of dynamical state in cortical network models",
  author   = "Huang, Chengcheng",
  journal  = "Curr. Opin. Neurobiol.",
  keywords = "context-dependent ;saturating non-linearities"
}

@ARTICLE{Duncker2020-uz,
  title    = "Organizing recurrent network dynamics by task-computation to
              enable continual learning",
  author   = "Duncker, Lea and Driscoll, Laura and Shenoy, Krishna V and
              Sahani, Maneesh and Sussillo, David",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  year     =  2020,
  keywords = "Neurips 2020;multi-task"
}

@ARTICLE{Cao2020-ba,
  title    = "Characterizing emergent representations in a space of candidate
              learning rules for deep networks",
  author   = "Cao, Yinan and Summerfield, Christopher and Saxe, Andrew",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  year     =  2020,
  keywords = "Neurips 2020"
}

@ARTICLE{Hope2020-qc,
  title     = "The economic consequences of major tax cuts for the rich",
  author    = "Hope, David and Limberg, Julian",
  abstract  = "This paper uses data from 18 OECD countries over the last five
               decades to estimate the causal effect of major tax cuts for the
               rich on income inequality, economic growth, and unemployment.
               First, we use a new encompassing measure of taxes on the rich to
               identify instances of major reduction in tax progressivity.
               Then, we look at the causal effect of these episodes on economic
               outcomes by applying a nonparametric generalization of the
               difference-in-differences indicator that implements Mahalanobis
               matching in panel data analysis. We find that major reforms
               reducings taxes on the rich lead to higher income inequality as
               measured by the top 1\% share of pre-tax national income. The
               effect remains stable in the medium term. In contrast, such
               reforms do not have any significant effect on economic growth
               and unemployment.",
  publisher = "London School of Economics and Political Science",
  number    =  55,
  pages     = "33",
  series    = "International Inequalities Institute Working Papers",
  month     =  dec,
  year      =  2020,
  address   = "London, UK",
  keywords  = "tax cuts for the rich, income inequality, growth, unemployment,
               difference-in-differences, Mahalanobis matching;economics",
  language  = "en"
}

@ARTICLE{Mikael_Lundqvis_Scott_L_Brincat_Jonas_Rose_Melissa_R_Warden_Tim_Buschman_Earl_K_Miller_Pawel_Herman_undated-vi,
  title    = "A {Hot-Coal} Theory of Working Memory",
  author   = "{Mikael Lundqvis, Scott L Brincat, Jonas Rose, Melissa R. Warden,
              Tim Buschman, Earl K. Miller, Pawel Herman}",
  keywords = "elife"
}

@ARTICLE{Bong2020-pn,
  title    = "Latent Dynamic Factor Analysis of {High-Dimensional} Neural
              Recordings",
  author   = "Bong, Heejong and Liu, Zongge and Ren, Zhao and Smith, Matthew
              and Ventura, Valerie and Robert, Kass E",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  year     =  2020,
  keywords = "Multi-area communication;methods;Neurips 2020"
}

@ARTICLE{Khona_undated-va,
  title    = "1 Attractor and integrator networks in the brain",
  author   = "Khona, Mikail and Fiete, Ila R",
  keywords = "Reviewer"
}

@ARTICLE{Van_Ede_Mark_Stokes_Kia_Nobre_Dr_Nicholas_E_Myers_undated-dt,
  title    = "Multiple and Dissociable Effects of Sensory History on
              {Working-Memory} Performance",
  author   = "van Ede , Mark Stokes , Kia Nobre , Dr. Nicholas E. Myers, Jasper
              Hajonides, Dr Freek",
  keywords = "Reviewer;elife"
}

@MISC{Rager2020-hv,
  title        = "The Structure and Dimension of Variability Across
                  {Multi-Area} Cortical Circuits",
  author       = "Rager, Danielle Marie",
  year         =  2020,
  howpublished = "Thesis",
  keywords     = "Multi-area communication"
}

@ARTICLE{Song2020-fo,
  title    = "Can the Brain Do {Backpropagation?---Exact} Implementation of
              Backpropagation in Predictive Coding Networks",
  author   = "Song, Yuhang and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz,
              Rafal",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  year     =  2020,
  keywords = "DL vs Brain;Neurips 2020"
}

@PHDTHESIS{Farrell_undated-dg,
  title    = "Revealing structure in trained neural networks through
              dimensionality-based methods",
  author   = "Farrell, Matthew S",
  keywords = "high-dimensionality"
}

@MISC{Cisek_undated-uc,
  title        = "Beyond the computer metaphor: Behavior as interaction",
  author       = "Cisek, Paul",
  howpublished = "\url{http://www.summer12.isc.uqam.ca/page/docs/readings/Cisek-Paul/Cisek-Beyond%20the%20computer%20metaphor.pdf}",
  note         = "Accessed: 2021-9-5",
  keywords     = "evolution"
}

@BOOK{Striedter2020-ct,
  title     = "Brains through time: A natural history of vertebrates",
  author    = "Striedter, Georg F and Northcutt, R Glenn",
  publisher = "Oxford University Press",
  month     =  mar,
  year      =  2020,
  address   = "New York, NY",
  keywords  = "evolution"
}

@ARTICLE{Proville_undated-vc,
  title    = "Flexible enhancement of task-relevant sounds by distinct neural
              cortical populations",
  author   = "Proville, R{\'e}mi and Rodgers, Chris and Boubenec, Yves",
  keywords = "R\&W"
}

@MISC{David_L_Barack_and_John_W_Krakauer_undated-ui,
  title  = "Two views on the cognitive brain",
  author = "{David L. Barack and John W. Krakauer}"
}

@article{Ahmadian2021,
  title={What is the dynamical regime of cerebral cortex?},
  author={Ahmadian, Yashar and Miller, Kenneth D},
  journal={Neuron},
  volume={109},
  number={21},
  pages={3373--3391},
  year={2021},
  publisher={Elsevier}
}